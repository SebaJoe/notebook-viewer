[
    {
        "title": "acs_cte_forward_model_example_assignment_colloquial_gpt-4o",
        "source": [
            {
                "type": "markdown",
                "text": "<a id=\"title_ID\"></a>\n# Pixel-based ACS/WFC CTE Forward Model\n\nThis notebook demonstrates preparing data for input into the ACS/WFC pixel-based CTE forward model and running the model.\n\n### Table of Contents\n\n[Introduction](#intro_ID) <br>\n[0. Install/update stenv](#update) <br>\n[1. Imports](#imports) <br>\n[2. Download data and reference files](#download) <br>\n[3. Create an image of artificial stars](#stars) <br>\n\n[Option A: Start with an observed FLC image](#option-a)\n - [4. Add artificial stars](#A4)\n - [5. Reverse the flat and dark correction](#A5)\n - [6. Run CTE forward model](#A6)\n - [7. (Optional) Run CTE correction](#A7)\n - [8. Apply flat and dark correction](#A8) <br>\n \n[Option B: Start with a synthetic image](#option-b)\n - [4. Create your image](#B4)\n - [5. Run CTE forward model](#B5)\n - [6. (Optional) Run CTE correction](#B6)\n - [7. Apply flat and dark correction](#B7) <br>\n\n[About this Notebook](#about_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"intro_ID\"></a>\n## Introduction\n\nThe charge transfer efficiency (CTE) of the Advanced Camera for Surveys (ACS) Wide Field Channel (WFC) has been decreasing over the lifetime of the instrument. Radiation damage from cosmic rays and other sources leads to charge traps within the detector. These traps remove electrons from charge packets as they are transferred between rows of the detector, and release the electrons in subsequent pixels. This causes flux to be removed from bright features and released into pixels behind the features (relative to the row closest to the amplifier), creating bright trails.\n\nA pixel-based CTE correction model for the ACS/WFC detector is fully described in [Anderson & Bedin (2010)](https://ui.adsabs.harvard.edu/abs/2010PASP..122.1035A/abstract), and a recent update to the model is presented in [ACS ISR 2018-04](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/instrument-science-reports-isrs/_documents/isr1804.pdf). The model is based on an empirical determination of the number and depth of charge traps distributed across the detector. It simulates detector readout of an input image, removes the result from the input, and iterates five times. In this way, a reverse model is successively approximated by the forward model. Electrons released in trails are removed and added back to the bright feature in which they originated.\n\nThe pixel-based correction was implemented in the calibration pipeline code for ACS (`CALACS`) in 2012 and the algorithm was updated and improved in 2018. The CTE correction step within `CALACS` runs on bias-corrected images, `blv_tmp` files, producing `blc_tmp` files, which lack the bright trails due to poor CTE. Further calibration, including dark correction and flat-fielding, produces `flt` and `flc` files from the `blv_tmp` and `blc_tmps` files, respectively. For more information on calibration of ACS/WFC data, see the [ACS Data Handbook](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/other-documents/_documents/acs_dhb.pdf).\n\nUsers desiring to more fully understand the effects of pixel-based CTE correction on their science may wish to run the forward model (i.e., the detector readout simulation) on data containing artificial stars. Here we demonstrate two methods for running the CTE forward model. In [Option A](#option-a), we begin with an observed `flc` image, whereas in [Option B](#option-b), we begin with a `raw` image and generate synthetic data on which to run the forward model.\n\n**Note: The forward model, like the CTE correction step in `CALACS`, adds 10% of the difference between the input and output `SCI` extensions to the `ERR` extensions to account for uncertainty in the CTE model. Below, we provide guidance for properly repopulating the `ERR` extensions of forward-modeled data.**"
            },
            {
                "type": "markdown",
                "text": "<a id=\"update\"></a>\n### 0. Install/update stenv\n\n#### *[AstroConda](https://astroconda.readthedocs.io/en/latest/) is no longer supported and is superseded by stenv.\n[stenv](https://stenv.readthedocs.io/en/latest/) will include most packages from AstroConda and is recommended to process and analyze data from the Hubble Space Telescope (HST) and James Webb Space Telescope (JWST). To install and activate stenv, please refer to the [documentation](https://stenv.readthedocs.io/en/latest/getting_started.html). NOTE: stenv requires Python 3.8 or greater.\n\nIf you already use stenv, make sure the versions of `hstcal` and [`acstools`](https://acstools.readthedocs.io/en/latest/) are both at least 2.1.0. The version of `CALACS` should be at least 10.1.0. Check the versions of all three on the command line:\n\n`$ conda list hstcal`\n\n`$ conda list acstools`\n\n`$ calacs.e --version`\n\nIt is recommended, however, that you use the most up-to-date versions of these packages. To update these packages, run the following via the command line:\n\n`$ conda update hstcal`\n\n`$ conda update acstools` "
            },
            {
                "type": "markdown",
                "text": "<a id=\"imports\"></a>\n### 1. Imports\n\nStart by importing several packages:\n\n- *matplotlib notebook* for creating interactive plots\n- *os* for setting environment variables\n- *shutil* for managing directories\n- *numpy* for math and array calculations\n- *matplotlib pyplot* for plotting\n- *matplotlib.colors LogNorm* for scaling images\n- *astropy.io fits* for working with FITS files\n- *photutils datasets* for creating synthetic stars and images\n- *astroquery.mast Observations* for downloading data from MAST\n- *acstools acsccd* for performing bias correction\n- *acstools acscte* for performing CTE correction (reversing CTE trailing)\n- *acstools acs2d* for performing dark correction and flat-fielding\n- *acstools acscteforwardmodel* for running CTE forward model (generating CTE trailing)"
            },
            {
                "type": "code",
                "text": "```python\n\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom astropy.io import fits\nfrom astropy.modeling.models import Gaussian2D\nfrom photutils.datasets import make_noise_image, make_model_params, make_model_image\nfrom astroquery.mast import Observations\nfrom acstools import acsccd\nfrom acstools import acscte\nfrom acstools import acs2d\nfrom acstools import acscteforwardmodel\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"download\"></a>\n### 2. Download data and reference files\n\nFull-frame, new-mode subarray, and 2K old-mode subarray ACS/WFC images can be run through the CTE forward model. New-mode subarrays were added to the HST flight software at the beginning of Cycle 24. These subarrays have `APERTURE` keywords of the type `WFC1A-512, WFC1A-1K, WFC1A-2K`, etc. Old-mode subarrays have `APERTURE` keywords of the type `WFC1-512, WFC1-1K, WFC1-2K`, etc. WFC apertures are also listed in [Table 7.7 of the ACS IHB](https://hst-docs.stsci.edu/display/ACSIHB/7.7+ACS+Apertures#id-7.7ACSApertures-table7.7).\n\nWe recommend that the CTE forward model be run on data that has been bias-corrected, but not dark-corrected or flat-fielded. The flat and dark should be present in the image input into the CTE forward model because these features are present in the image when it is read out, and are therefore affected by CTE losses. The forward model can be run on `flc` files, but the results will technically be incorrect. Photometric tests of forward modeled data of both types show minor differences. Post-SM4 subarray data must be destriped with [`acs_destripe_plus`](https://acstools.readthedocs.io/en/latest/api/acstools.acs_destripe_plus.destripe_plus.html#acstools.acs_destripe_plus.destripe_plus),  which will also perform the other calibration steps. **Note: At this time, `acs_destripe_plus` only produces `flt`/`flc` images.**"
            },
            {
                "type": "markdown",
                "text": "We download a full-frame 47 Tuc image, `jd0q14ctq`, from the ACS CCD Stability Monitor program (PI: Coe, 14402) from the Mikulski Archive for Space Telescopes ([MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html)) using [astroquery](https://astroquery.readthedocs.io/en/latest/). This image was taken in March 2016, and so it is strongly affected by CTE losses. We download the `flc` image for [Option A](#option-a) and the `raw` image for [Option B](#option-b) into the current directory."
            },
            {
                "type": "code",
                "text": "```python\n\nobs_table = Observations.query_criteria(obs_id='jd0q14ctq')\n\ndl_table = Observations.download_products(obs_table['obsid'], mrp_only=False,\n                                          productSubGroupDescription=['FLC', 'RAW'])\n\nfor row in dl_table:\n    oldfname = row['Local Path']\n    unique_fname = np.unique(oldfname)\n    newfname = os.path.basename(oldfname)\n    print(row)\n    os.rename(oldfname, newfname)\n    \nshutil.rmtree('mastDownload')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, update and download the correct flat and dark reference files for the `jd0q14ctq` dataset from the [Calibration Reference Data System](https://hst-crds.stsci.edu/) (CRDS). We use the [CRDS command line tools](https://hst-crds.stsci.edu/static/users_guide/command_line_tools.html#crds-bestrefs) to do this."
            },
            {
                "type": "code",
                "text": "```python\n\nos.environ['CRDS_SERVER'] = 'https://hst-crds.stsci.edu'\nos.environ['CRDS_PATH'] = './crds_cache'\nos.environ['jref'] = './crds_cache/references/hst/acs/'\n\n!crds bestrefs --update-bestrefs --sync-references=1 --files jd0q14ctq_flc.fits\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we obtain the filenames of the flat (`PFLTFILE`), CTE-corrected dark (`DRKCFILE`), and superbias (`BIASFILE`) reference files from the image header. The flat will be used to add the effects of the flat field back into the image. If the data were post-flashed, then the flash file (`FLSHFILE`) is needed as well. This is shown in the commented line below. The CTE-corrected dark will be used to add dark current to the `flc` file and the synthetic data. The superbias will be used to repopulate the `ERR` extensions of the forward-modeled image."
            },
            {
                "type": "code",
                "text": "```python\n\nhdr = fits.getheader('jd0q14ctq_flc.fits')\n\nflat = hdr['PFLTFILE'].split('$')[-1]\ndkc = hdr['DRKCFILE'].split('$')[-1]\nbias = hdr['BIASFILE'].split('$')[-1]\n# flash = hdr['FLSHFILE'].split('$')[-1]\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We open the flat and dark images and obtain the `SCI` extensions of both CCDs, which are extension 1 for WFC2 and extension 4 for WFC1. We open the superbias image and obtain the `ERR` extensions of both CCDs, which are extension 2 for WFC2 and extension 5 for WFC2. If the flash file is needed, obtain the `SCI` extensions for both CCDs. This is shown in the commented out lines below."
            },
            {
                "type": "code",
                "text": "```python\n\n# The jref environment variable gives the directory containing the reference files\nflat_hdu = fits.open('{}/{}'.format(os.environ['jref'], flat))\n\nflat_wfc1 = flat_hdu[4].data\nflat_wfc2 = flat_hdu[1].data\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\ndkc_hdu = fits.open('{}/{}'.format(os.environ['jref'], dkc))\n\ndkc_wfc1 = dkc_hdu[4].data\ndkc_wfc2 = dkc_hdu[1].data\n\n# Darks can sometimes have negative pixels because they have been flash-corrected \n# and CTE-corrected. Set all negative pixels to zero\ndkc_wfc1[dkc_wfc1 < 0.] = 0.\ndkc_wfc2[dkc_wfc2 < 0.] = 0.\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nbias_hdu = fits.open('{}/{}'.format(os.environ['jref'], bias))\n\nerr_bias_wfc1 = bias_hdu[5].data\nerr_bias_wfc2 = bias_hdu[2].data\n\ndq_bias_wfc1 = bias_hdu[6].data\ndq_bias_wfc2 = bias_hdu[3].data\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\n# flash_dhu = fits.open('{}/{}'.format(os.environ['jref'], flash))\n\n# flash_wfc1 = flash_hdu[4].data\n# flash_wfc2 = flash_hdu[1].data\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"stars\"></a>\n### 3. Create image of artificial stars\n\nWe will need an image containing artificial stars on zero background for both options presented below. Artificial stars are typically generated using models that do not include the flat field, or are produced from data that have been flat-fielded. If this is the case, artificial stars should be added to the image at the `flc` stage.\n\nUsers of this notebook may have a preferred method for generating artificial stars and adding them to data, so here we simply add several Gaussians to the image using utilities within `photutils.datasets` in `astropy`. These Gaussians are not representative of the true ACS/WFC PSF, and are added here for illustrative purposes only. Please note that artificial sources with peak values approaching or exceeding the WFC CCD full well value of about 80,000 electrons are not recommended for simulated data. Blooming of charge from saturated pixels is not implemented in this example.\n\nThere are many tools for generating artificial stars, including [Tiny Tim](http://www.stsci.edu/hst/instrumentation/focus-and-pointing/focus/tiny-tim-hst-psf-modeling), [effective PSFs](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/instrument-science-reports-isrs/_documents/isr0601.pdf), or [`EPSFBuilder`](https://photutils.readthedocs.io/en/stable/epsf.html) in `photutils`. A recent study of PSF models for ACS/WFC can be found [here](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/instrument-science-reports-isrs/_documents/isr1708.pdf)."
            },
            {
                "type": "markdown",
                "text": "First, we generate a table of random Gaussian sources of typical brightness for our 47 Tuc field with $\\mathrm{FWHM}\\sim2.5$ pixels. Because $\\mathrm{FWHM} = 2.355\\sigma$, we will generate Gaussian sources with $\\sigma \\sim 1.06$ pixels in both $x$ and $y$. We get use the shape of one of the flc image SCI extensions for creating the (x, y) coordinates of the sources."
            },
            {
                "type": "code",
                "text": "```python\n\nwfc2 = fits.getdata('jd0q14ctq_flc.fits', ext=1)\n\nshape = wfc2.shape\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nn_sources = 300\n\nsources = make_model_params(shape, n_sources, x_name='x_mean', y_name='y_mean',\n                            amplitude=(500, 30000), x_stddev=(1.05, 1.07), \n                            y_stddev=(1.05, 1.07), theta=(0, np.pi), seed=12345)\n\nsources\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we make an image from the table of Gaussian sources. Finally, we run the synthetic image through a Poisson sampler in order to simulate the Poisson noise of the scene."
            },
            {
                "type": "code",
                "text": "```python\n\nmodel = Gaussian2D()\nsynth_stars_image = make_model_image(shape, model, sources, \n                                     x_name='x_mean', y_name='y_mean', progress_bar=True)\n\nsynth_stars_image = np.random.poisson(synth_stars_image)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth_stars_image, vmin=0, vmax=200, interpolation='nearest', \n          cmap='Greys_r', origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=10, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id=\"option-a\"></a>\n### Option A: Start with an observed FLC image\n\nIn this Option, we add synthetic stars to the scene in an `flc` image and process it appropriately for use with the forward model. We use the `flc` image because it is the closest approximation to a pristine image of the sky. Below we plot a portion of the downloaded 47 Tuc image. Stars of various magnitudes are visible, as well as cosmic rays."
            },
            {
                "type": "code",
                "text": "```python\n\nflc = fits.getdata('jd0q14ctq_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flc, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', origin='lower')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"A4\"></a>\n### 4A. Add artificial stars\n\nAdd the image of artificial stars generated above to both CCDs of the `flc` image, and save it as a new file."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('jd0q14ctq_flc.fits')\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 += synth_stars_image\nwfc2 += synth_stars_image\n\nhdu.writeto('jd0q14ctq_stars_flc.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Below we plot a section of the `flc` image with a few artificial stars circled in red."
            },
            {
                "type": "code",
                "text": "```python\n\nflc_stars = fits.getdata('jd0q14ctq_stars_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flc_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"A5\"></a>\n### 5A. Reverse the flat and dark correction\n\nFirst, calculate the total exposure time of the 47 Tuc image by combining the exposure time, flash time (if any), and 3 seconds of extra dark time to approximate instrument commanding overheads."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('jd0q14ctq_stars_flc.fits')\n\nhdr = hdu[0].header\n\nexptime = hdr['EXPTIME']\nflashtime = hdr['FLASHDUR']\ndarktime = exptime + flashtime + 3\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we open the 47 Tuc image and obtain the `SCI` extensions of both CCDs. We multiply by the flat and scale the CTE-corrected dark by the total exposure time. We also run the scaled dark image through a Poisson sampler to include Poisson noise in the dark scene. We then add the dark current to the image. We save the result, which is now effectively a `blc_tmp` file. If the data are post-flashed, we also need to reverse the flash correction. We do this by multiplying the flash file by the flash duration, running it through a Poisson sampler, and adding it to the 47 Tuc image. The lines for this are commented out below. **Note: It is not recommended to use a simulated exposure time that scales pixels in the dark or flash image to or above the full well depth of ~80,000 electrons.**"
            },
            {
                "type": "code",
                "text": "```python\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 *= flat_wfc1\nwfc2 *= flat_wfc2\n\nwfc1 += np.random.poisson(dkc_wfc1*darktime)\nwfc2 += np.random.poisson(dkc_wfc2*darktime)\n\n# wfc1 += np.random.poisson(flash_wfc1*flashtime)\n# wfc2 += np.random.poisson(flash_wfc2*flashtime)\n\nhdu.writeto('jd0q14ctq_stars_pfl_dkc.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": " Finally, we update the header keyword `PCTECORR` to `PERFORM`, which is necessary for running the forward model."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_pfl_dkc.fits', 'PCTECORR', value='PERFORM')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"A6\"></a>\n### 6A. Run CTE forward model\n\nWe are now ready to run the CTE forward model, which simulates the effects of CTE losses while reading out the detector. In this example, we will use the `acstools` module `acscteforwardmodel`. Note that this step may take a few minutes. The resulting filename will be `*_ctefmod.fits`. We rename the file to have the suffix `*_blv_tmp.fits` so that it can be processed by `CALACS` in a later step."
            },
            {
                "type": "code",
                "text": "```python\n\nacscteforwardmodel.acscteforwardmodel('jd0q14ctq_stars_pfl_dkc.fits')\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nos.rename('jd0q14ctq_stars_pfl_dkc_ctefmod.fits', 'jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "After the forward model is run, the `SCI` extensions of the image are equivalent to a `blv_tmp` file, in principle. However, the `ERR` extensions are the original `flc` `ERR` extensions plus 10% of the forward model correction. To ensure the `ERR` extensions are accurate for a `blv_tmp` file, we will set every pixel to zero and calculate new values for each pixel according to\n\n$\\mathrm{ERR} = \\sqrt{\\mathrm{SCI} + \\mathrm{RN}^2 + (\\mathrm{ERR}_{\\mathrm{superbias}}g)^2}$,\n\nwhere $\\mathrm{SCI}$ is the pixel value in the `SCI` extension (all negative pixels are set to zero), $\\mathrm{RN}$ is the readnoise, $\\mathrm{ERR}_{\\mathrm{superbias}}$ is the pixel value in the `ERR` extension of the superbias, and $g$ is the gain.\n\nFirst, we access the header and `SCI` and `ERR` extensions of the forward-modeled data."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\nsci_wfc1 = hdu[4].data\nsci_wfc2 = hdu[1].data\n\nerr_wfc1 = hdu[5].data\nerr_wfc2 = hdu[2].data\n\nhdr = hdu[0].header\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we take the readnoise and gain values for each quadrant from the header."
            },
            {
                "type": "code",
                "text": "```python\n\nrn_A = hdr['READNSEA']\nrn_B = hdr['READNSEB']\nrn_C = hdr['READNSEC']\nrn_D = hdr['READNSED']\n\ngain_A = hdr['ATODGNA']\ngain_B = hdr['ATODGNB']\ngain_C = hdr['ATODGNC']\ngain_D = hdr['ATODGND']\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Finally, we make copies of the `SCI` extensions in which to set all negative values to zero. We calculate the appropriate error for each quadrant and save them to the `ERR` extensions of the forward-modeled image."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1_pos = np.copy(sci_wfc1)\nsci_wfc2_pos = np.copy(sci_wfc2)\n\nsci_wfc1_pos[sci_wfc1_pos < 0] = 0\nsci_wfc2_pos[sci_wfc2_pos < 0] = 0\n\nerr_A = np.sqrt(sci_wfc1_pos[:, :2048] + rn_A**2 + (err_bias_wfc1[20:, 24:2072]*gain_A)**2)\nerr_B = np.sqrt(sci_wfc1_pos[:, 2048:] + rn_B**2 + (err_bias_wfc1[20:, 2072:-24]*gain_B)**2)\nerr_C = np.sqrt(sci_wfc2_pos[:, :2048] + rn_C**2 + (err_bias_wfc2[:-20, 24:2072]*gain_C)**2)\nerr_D = np.sqrt(sci_wfc2_pos[:, 2048:] + rn_D**2 + (err_bias_wfc2[:-20, 2072:-24]*gain_D)**2)\n\nerr_wfc1[:] = np.hstack((err_A, err_B))\nerr_wfc2[:] = np.hstack((err_C, err_D))\n\nhdu.writeto('jd0q14ctq_stars_ctefmod_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"A7\"></a>\n### (Optional) 7A. Run CTE correction\n\nIf desired, we now CTE correct the forward-modeled image. To do this, we need to update the `PCTECORR` keyword to `PERFORM` again and update the `NEXTEND` keyword to 6, the number of extensions left after running the forward model.  (This is because the forward model strips the distortion-related extensions from the input file, but does not update `NEXTEND`.) Finally, run `acscte` on the image. The resulting filename will be `*_blc_tmp.fits`."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'PCTECORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'NEXTEND', value=6)\n\nacscte.acscte('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id=\"A8\"></a>\n### 8A. Apply flat and dark correction\n\nFinally, we flat-field and dark-correct the forward-modeled image using `acs2d` to produce an `flt`-like image. First, we update the keywords `DARKCORR` and `FLATCORR` to `PERFORM`. All other relevant `CALACS` header keyword switches are set to `COMPLETE` because the original data was an `flc` image. The resulting filename will be `*_flt.fits`. **Note:** If the data were post-flashed, and the flash background was added back in during an earlier step, we must also set `FLSHCORR` equal to `PERFORM`. This option is shown below in a commented out line."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If the forward-modeled image was CTE-corrected in [Step 7A](#A7), we run `acs2d` on the CTE-corrected image. The resulting filename will be `*_flc.fits`."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blc_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blc_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('jd0q14ctq_stars_ctefmod_blc_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "The 47 Tuc image(s) are now prepared for further analysis appropriate for the user's science. The cells below plot a portion of the final images, the `flt` and, if produced, the `flc`."
            },
            {
                "type": "code",
                "text": "```python\n\nflt_stars = fits.getdata('jd0q14ctq_stars_ctefmod_flt.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flt_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nflc_stars = fits.getdata('jd0q14ctq_stars_ctefmod_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flc_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"option-b\"></a>\n### Option B: Start with a synthetic image\n\nIn this Option, we start with the `raw` file from the `jd0q14ctq` dataset and process the `SCI` extensions to make a completely synthetic dataset. We then process it appropriately for use in the forward model.\n\n<a id=\"B4\"></a>\n### 4B. Create a synthetic image\n\nWe will create an image that is equivalent to a `blc_tmp` file. This means that the image is not flat-fielded and includes sky background, Poisson noise from the sky, artificial stars or other sources, Poisson noise from the sources, dark current, and dark noise.\n\nWe first process the data with `acsccd` within `acstools` to create a `blv_tmp`. This ensures that the error (`ERR`) and data quality (`DQ`) extensions are created and the header keywords for every extension are initially populated, which is necessary for the CTE forward model to run."
            },
            {
                "type": "code",
                "text": "```python\n\nacsccd.acsccd('jd0q14ctq_raw.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we obtain the `SCI` extensions from the `blv_tmp` file, and set the pixels to zero."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('jd0q14ctq_blv_tmp.fits')\n    \nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1[:] = np.zeros(shape)\nwfc2[:] = np.zeros(shape)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We then generate an image containing a user-selected sky background level (here we choose 40 electrons arbitrarily) and Poisson noise. Finally, we sum the noise image and the artificial star image, and save the result as a new file."
            },
            {
                "type": "code",
                "text": "```python\n\nnoise_image = make_noise_image(shape, distribution='poisson', mean=40, seed=12345)\n\nwfc1 += noise_image + synth_stars_image\nwfc2 += noise_image + synth_stars_image\n\nhdu.writeto('synth.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Below we plot a portion of the synthetic image, with sources circled in red."
            },
            {
                "type": "code",
                "text": "```python\n\nsynth = fits.getdata('synth.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "In order to properly remove the dark current after the forward model is run, we update the exposure time and flash duration header keywords, `EXPTIME` and `FLASHDUR`, with the desired simulated exposure time. The total exposure time used for the dark correction is the combination of exposure time, flash duration, and overhead (which depends on whether the data are post-flashed or not). Here we set `EXPTIME` to 300 seconds and `FLASHDUR` to 0 seconds. In principle one should retrieve the overheads from CCDTAB, but we provide a simpler approach here. Please note that the overhead times may change."
            },
            {
                "type": "code",
                "text": "```python\n\nexptime = 300.\nflashdur = 0.\n\nhdu = fits.open('synth.fits')\n\nhdr = hdu[0].header\n\nhdr['EXPTIME'] = exptime\nhdr['FLASHDUR'] = flashdur\n\nif flashdur > 0:\n    overhead = 2.43\nelse:\n    overhead = 0.21\n\ndarktime = exptime + flashdur + overhead\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We need to update the FITS header with the correct dark time for use in a later step. **However, we leave off the overhead, because ACSCCD (run in a later step) will automatically append the overhead to the dark time in the header.** We still use the darktime variable with overhead to manually add the dark current to our model below."
            },
            {
                "type": "code",
                "text": "```python\n\nhdr['DARKTIME'] = darktime - overhead\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, obtain the `SCI` extensions of both CCDs. We then multiply by the flat and scale the CTE-corrected dark by a chosen exposure time. We also run the scaled dark image through a Poisson sampler to include Poisson noise in the dark scene. We then add the dark current to the image. If post-flash is desired, multiply the flash reference file by the flash duration, run it through a Poisson sampler, and add to the synthetic data. This is shown in the commented out lines below. We save the result, which is now effectively a `blc_tmp` file. **Note: It is not recommended to use a simulated exposure time that scales pixels in the dark or flash image to or above the full well depth of ~80,000 electrons.**\n\nNote that these reference files are specific to the anneal cycle in which these data were taken. If an observation date other than that listed in the `DATE-OBS` header keyword is desired for the synthetic data, different reference files will be needed. These can be found by updating the `DATE-OBS` header keyword in the synthetic image to the desired observation date, and rerunning the cell in [Step 2](#download) which uses `CRDS bestrefs` to download the correct reference files."
            },
            {
                "type": "code",
                "text": "```python\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 *= flat_wfc1\nwfc2 *= flat_wfc2\n\nwfc1 += np.random.poisson(dkc_wfc1*darktime)\nwfc2 += np.random.poisson(dkc_wfc2*darktime)\n\n# wfc1 += np.random.poisson(flash_wfc1*flashdur)\n# wfc2 += np.random.poisson(flash_wfc2*flashdur)\n\nhdu.writeto('synth_blc_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"B5\"></a>\n### 5B. Run CTE forward model\n\nWe are now ready to run the CTE forward model, which simulates the effects of CTE losses while reading out the detector. In this example, we will use the `acstools` module `acscteforwardmodel`. Note that this step may take a few minutes. The resulting filename will be `*_ctefmod.fits`. We rename this to `*_blv_tmp.fits` in order to ensure the correct behavior from `acs2d` in a later step."
            },
            {
                "type": "code",
                "text": "```python\n\nacscteforwardmodel.acscteforwardmodel('synth_blc_tmp.fits')\n\nos.rename('synth_blc_tmp_ctefmod.fits', 'synth_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "At this point, we also add readnoise to the forward-modeled `SCI` extensions to complete the readout simulation. We find the readnoise values for each quadrant of the image from the header keywords `READNSEA`, `READNSEB`, etc. We make a noise image for each quadrant, concatenate quadrants A and B and quadrants C and D, and add them to the synthetic image."
            },
            {
                "type": "code",
                "text": "```python\n\nrn_A = hdr['READNSEA']\nrn_B = hdr['READNSEB']\nrn_C = hdr['READNSEC']\nrn_D = hdr['READNSED']\n\nimg_rn_A = make_noise_image((shape[0], int(shape[1]/2)), distribution='gaussian', \n                            mean=0., stddev=rn_A)\nimg_rn_B = make_noise_image((shape[0], int(shape[1]/2)), distribution='gaussian', \n                            mean=0., stddev=rn_B)\nimg_rn_C = make_noise_image((shape[0], int(shape[1]/2)), distribution='gaussian', \n                            mean=0., stddev=rn_C)\nimg_rn_D = make_noise_image((shape[0], int(shape[1]/2)), distribution='gaussian', \n                            mean=0., stddev=rn_D)\n\nwfc1_rn = np.hstack((img_rn_A, img_rn_B))\nwfc2_rn = np.hstack((img_rn_C, img_rn_D))\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_blv_tmp.fits')\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 += wfc1_rn\nwfc2 += wfc2_rn\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "The `SCI` extensions of this image are now equivalent to a `blv_tmp` file, in principle. However, the `ERR` extensions are the original `blv_tmp` `ERR` extensions plus 10% of the forward model correction. To ensure the `ERR` extensions are accurate, we will calculate new values for each pixel according to\n\n$\\mathrm{ERR} = \\sqrt{\\mathrm{SCI} + \\mathrm{RN}^2 + (\\mathrm{ERR}_{\\mathrm{superbias}}g)^2}$,\n\nwhere $\\mathrm{SCI}$ is the pixel value in the `SCI` extension (all negative pixels are set to zero), $\\mathrm{RN}$ is the readnoise, $\\mathrm{ERR}_{\\mathrm{superbias}}$ is the pixel value in the `ERR` extension of the superbias, and $g$ is the gain.\n\nFirst, we access the header and `SCI` and `ERR` extensions of the forward-modeled data."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_rn_blv_tmp.fits')\n\nsci_wfc1 = hdu[4].data\nsci_wfc2 = hdu[1].data\n\nerr_wfc1 = hdu[5].data\nerr_wfc2 = hdu[2].data\n\nhdr = hdu[0].header\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, we take the readnoise and gain values for each quadrant from the header."
            },
            {
                "type": "code",
                "text": "```python\n\nrn_A = hdr['READNSEA']\nrn_B = hdr['READNSEB']\nrn_C = hdr['READNSEC']\nrn_D = hdr['READNSED']\n\ngain_A = hdr['ATODGNA']\ngain_B = hdr['ATODGNB']\ngain_C = hdr['ATODGNC']\ngain_D = hdr['ATODGND']\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Finally, we make copies of the `SCI` extensions in which to set all negative values to zero. We calculate the appropriate error for each quadrant and save them to the `ERR` extensions of the forward-modeled image."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1_pos = np.copy(sci_wfc1)\nsci_wfc2_pos = np.copy(sci_wfc2)\n\nsci_wfc1_pos[sci_wfc1_pos < 0] = 0\nsci_wfc2_pos[sci_wfc2_pos < 0] = 0\n\n# The superbias ERR arrays contain 20 rows of virtual overscan at the edge of \n# each CCD furthest from the amplifier and 24 columns of physical prescan on the\n# left and right edges.\nerr_A = np.sqrt(sci_wfc1_pos[:, :2048] + rn_A**2 + (err_bias_wfc1[20:, 24:2072]*gain_A)**2)\nerr_B = np.sqrt(sci_wfc1_pos[:, 2048:] + rn_B**2 + (err_bias_wfc1[20:, 2072:-24]*gain_B)**2)\nerr_C = np.sqrt(sci_wfc2_pos[:, :2048] + rn_C**2 + (err_bias_wfc2[:-20, 24:2072]*gain_C)**2)\nerr_D = np.sqrt(sci_wfc2_pos[:, 2048:] + rn_D**2 + (err_bias_wfc2[:-20, 2072:-24]*gain_D)**2)\n\nerr_wfc1[:] = np.hstack((err_A, err_B))\nerr_wfc2[:] = np.hstack((err_C, err_D))\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We also repopulate the DQ extensions because they reflect the processing of the original `blv_tmp` `SCI` extensions. To do this, we reprocess the data with `DQICORR` and `SINKCORR`, both within `acsccd`, and add in the DQ extensions of the appropriate superbias file. First, we rename the synthetic image to have a filename `*_raw.fits`, or `acsccd` will fail. Then, we update the `DQICORR` and `SINKCORR` header keywords to `PERFORM` and run `acsccd`. The output will be `*_blv_tmp.fits` again.\n\nThis step will also add the proper overhead to `DARKTIME` header keyword, but only if using CALACS v10.3.3 or later. We first check the version."
            },
            {
                "type": "code",
                "text": "```python\n\nos.system('calacs.e --version')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If your version of CALCACS is prior to v10.3.3, please update. Now let's run ACSCCD."
            },
            {
                "type": "code",
                "text": "```python\n\nos.rename('synth_ctefmod_rn_blv_tmp.fits', 'synth_ctefmod_rn_raw.fits')\n\nfits.setval('synth_ctefmod_rn_raw.fits', 'DQICORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_raw.fits', 'SINKCORR', value='PERFORM')\n\nacsccd.acsccd('synth_ctefmod_rn_raw.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Next, obtain the DQ extensions of the superbias file, and add them to the new DQ extensions of the synthetic data with a `bitwise_or` operator. "
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_rn_blv_tmp.fits')\n\ndq_wfc1 = hdu[6].data\ndq_wfc2 = hdu[3].data\n\ndq_wfc1[:] = np.bitwise_or(dq_wfc1, dq_bias_wfc1[20:, 24:-24])\ndq_wfc2[:] = np.bitwise_or(dq_wfc2, dq_bias_wfc2[:-20, 24:-24])\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Also, acsccd assumes the input image is in DN and converts it to counts by multiplying by the gain. We defined our model in electrons though, so the acsccd conversion to electrons was unnecessary. We divide by the gains to fix this and replace the image."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1 = hdu[4].data\nsci_wfc2 = hdu[1].data\n\nsci_wfc1[:, :2048] /= gain_A\nsci_wfc1[:, 2048:] /= gain_B\nsci_wfc2[:, :2048] /= gain_C\nsci_wfc2[:, 2048:] /= gain_D\n\nerr_wfc1 = hdu[5].data\nerr_wfc2 = hdu[2].data\n\nerr_wfc1[:, :2048] /= gain_A\nerr_wfc1[:, 2048:] /= gain_B\nerr_wfc2[:, :2048] /= gain_C\nerr_wfc2[:, 2048:] /= gain_D\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "[Top of Page](#title_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"B6\"></a>\n### 6B. (Optional) Run CTE correction\n\nIf desired, we now CTE correct the forward-modeled image. To do this, we need to update the `PCTECORR` keyword to `PERFORM` again, and run `acscte` on the image. The resulting filename will be `*_blc_tmp.fits`."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'PCTECORR', value='PERFORM')\n\nacscte.acscte('synth_ctefmod_rn_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id=\"B7\"></a>\n### 7B. Apply flat and dark correction\n\nFinally, we flat-field and dark-correct the forward-modeled image using `acs2d` to produce an `flt`-like image. We first ensure that the `DARKCORR`, `FLATCORR`, and if necessary, `FLSHCORR` header keywords are set to `PERFORM`. The resulting filename will be `*_flt.fits`."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('synth_ctefmod_rn_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('synth_ctefmod_rn_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If the forward-modeled image was CTE-corrected in [Step 6](#B6), we run `acs2d` on the CTE-corrected image. The resulting filename will be `*_flc.fits`."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blc_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_blc_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('synth_ctefmod_rn_blc_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('synth_ctefmod_rn_blc_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "The image(s) are now prepared for further analysis appropriate for the user's science. The cells below plot a portion of the final images, the `flt` and, if produced, the `flc`."
            },
            {
                "type": "code",
                "text": "```python\n\nsynth_ctefmod = fits.getdata('synth_ctefmod_rn_flt.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth_ctefmod, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nsynth_ctefmod_flc = fits.getdata('synth_ctefmod_rn_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth_ctefmod_flc, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### For more help:\n\nMore details may be found on the [ACS website](http://www.stsci.edu/hst/instrumentation/acs) and in the [ACS Instrument](https://hst-docs.stsci.edu/display/ACSIHB) and [Data Handbooks](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/other-documents/_documents/acs_dhb.pdf).\n\nPlease visit the [HST Help Desk](http://hsthelp.stsci.edu). Through the help desk portal, you can explore the HST Knowledge Base and request additional help from experts."
            },
            {
                "type": "markdown",
                "text": "<a id=\"about_ID\"></a>\n### About this Notebook\n**Author:** Jenna Ryon, ACS Instrument Team <br>\n**Updated On:** 04/21/2022\n\n---\n\n[Top of Page](#title_ID)\n<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n<br></br>\n<br></br>"
            },
            {
                "type": "code",
                "text": "```python\n\n\n\n```",
                "output": ""
            }
        ],
        "target": [
            {
                "type": "markdown",
                "text": "<a id=\"title_ID\"></a>\n# Pixel-based ACS/WFC CTE Forward Model\n\nThis notebook demonstrates preparing data for input into the ACS/WFC pixel-based CTE forward model and running the model.\n\n### Table of Contents\n\n[Introduction](#intro_ID) <br>\n[0. Install/update stenv](#update) <br>\n[1. Imports](#imports) <br>\n[2. Download data and reference files](#download) <br>\n[3. Create an image of artificial stars](#stars) <br>\n\n[Option A: Start with an observed FLC image](#option-a)\n - [4. Add artificial stars](#A4)\n - [5. Reverse the flat and dark correction](#A5)\n - [6. Run CTE forward model](#A6)\n - [7. (Optional) Run CTE correction](#A7)\n - [8. Apply flat and dark correction](#A8) <br>\n \n[Option B: Start with a synthetic image](#option-b)\n - [4. Create your image](#B4)\n - [5. Run CTE forward model](#B5)\n - [6. (Optional) Run CTE correction](#B6)\n - [7. Apply flat and dark correction](#B7) <br>\n\n[About this Notebook](#about_ID)"
            },
            {
                "type": "markdown",
                "text": "<a id=\"intro_ID\"></a>\n## Introduction\n\nThe charge transfer efficiency (CTE) of the Advanced Camera for Surveys (ACS) Wide Field Channel (WFC) has been decreasing over the lifetime of the instrument. Radiation damage from cosmic rays and other sources leads to charge traps within the detector. These traps remove electrons from charge packets as they are transferred between rows of the detector, and release the electrons in subsequent pixels. This causes flux to be removed from bright features and released into pixels behind the features (relative to the row closest to the amplifier), creating bright trails.\n\nA pixel-based CTE correction model for the ACS/WFC detector is fully described in [Anderson & Bedin (2010)](https://ui.adsabs.harvard.edu/abs/2010PASP..122.1035A/abstract), and a recent update to the model is presented in [ACS ISR 2018-04](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/instrument-science-reports-isrs/_documents/isr1804.pdf). The model is based on an empirical determination of the number and depth of charge traps distributed across the detector. It simulates detector readout of an input image, removes the result from the input, and iterates five times. In this way, a reverse model is successively approximated by the forward model. Electrons released in trails are removed and added back to the bright feature in which they originated.\n\nThe pixel-based correction was implemented in the calibration pipeline code for ACS (`CALACS`) in 2012 and the algorithm was updated and improved in 2018. The CTE correction step within `CALACS` runs on bias-corrected images, `blv_tmp` files, producing `blc_tmp` files, which lack the bright trails due to poor CTE. Further calibration, including dark correction and flat-fielding, produces `flt` and `flc` files from the `blv_tmp` and `blc_tmps` files, respectively. For more information on calibration of ACS/WFC data, see the [ACS Data Handbook](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/other-documents/_documents/acs_dhb.pdf).\n\nUsers desiring to more fully understand the effects of pixel-based CTE correction on their science may wish to run the forward model (i.e., the detector readout simulation) on data containing artificial stars. Here we demonstrate two methods for running the CTE forward model. In [Option A](#option-a), we begin with an observed `flc` image, whereas in [Option B](#option-b), we begin with a `raw` image and generate synthetic data on which to run the forward model.\n\n**Note: The forward model, like the CTE correction step in `CALACS`, adds 10% of the difference between the input and output `SCI` extensions to the `ERR` extensions to account for uncertainty in the CTE model. Below, we provide guidance for properly repopulating the `ERR` extensions of forward-modeled data.**"
            },
            {
                "type": "markdown",
                "text": "<a id=\"update\"></a>\n### 0. Install/update stenv\n\n#### *[AstroConda](https://astroconda.readthedocs.io/en/latest/) is no longer supported and is superseded by stenv.\n[stenv](https://stenv.readthedocs.io/en/latest/) will include most packages from AstroConda and is recommended to process and analyze data from the Hubble Space Telescope (HST) and James Webb Space Telescope (JWST). To install and activate stenv, please refer to the [documentation](https://stenv.readthedocs.io/en/latest/getting_started.html). NOTE: stenv requires Python 3.8 or greater.\n\nIf you already use stenv, make sure the versions of `hstcal` and [`acstools`](https://acstools.readthedocs.io/en/latest/) are both at least 2.1.0. The version of `CALACS` should be at least 10.1.0. Check the versions of all three on the command line:\n\n`$ conda list hstcal`\n\n`$ conda list acstools`\n\n`$ calacs.e --version`\n\nIt is recommended, however, that you use the most up-to-date versions of these packages. To update these packages, run the following via the command line:\n\n`$ conda update hstcal`\n\n`$ conda update acstools`"
            },
            {
                "type": "markdown",
                "text": "### 1. Imports\nImport the necessary scientific computing and data processing libraries required for analyzing ACS/WFC data and implementing the pixel-based CTE forward model. These imports will be crucial for managing file handling, numerical analysis, image processing, and external data retrieval."
            },
            {
                "type": "code",
                "text": "```python\n\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom astropy.io import fits\nfrom astropy.modeling.models import Gaussian2D\nfrom photutils.datasets import make_noise_image, make_model_params, make_model_image\nfrom astroquery.mast import Observations\nfrom acstools import acsccd\nfrom acstools import acscte\nfrom acstools import acs2d\nfrom acstools import acscteforwardmodel\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 2. Download data and reference files\nDownload a full-frame ACS/WFC image from the MAST archive using `astroquery`. Retrieve both the `flc` image for Option A and the `raw` image for Option B of the observation with ID `jd0q14ctq`. Make sure the files are correctly renamed and the temporary directories removed after download."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom astroquery.mast import Observations\nimport os\nimport shutil\n\n# Define the target observation ID and create a temporary directory for downloads\nobs_id = 'jd0q14ctq'\ntemp_dir = 'temp_download'\n\n# Create directory if not exists\nif not os.path.exists(temp_dir):\n    os.makedirs(temp_dir)\n\n# Search for the observation\nobs_table = Observations.query_criteria(obs_id=obs_id)\n\n# Ensure observation is found\nif not obs_table:\n    raise ValueError(f'No observations found for ID {obs_id}')\n\n# Download products\nproducts = Observations.get_product_list(obs_table)\nObservations.download_products(products, mrp_only=False, download_dir=temp_dir)\n\n# Files to be retained with proper naming\nfinal_files = {'_flc': f'{obs_id}_flc.fits', '_raw': f'{obs_id}_raw.fits'}\n\n# Rename the relevant files and remove the rest\nfor prod in products:\n    for suffix, final_name in final_files.items():\n        if suffix in prod['productFilename']:\n            shutil.move(os.path.join(temp_dir, prod['productFilename']), final_name)\n\n# Clean up temporary download directory\nshutil.rmtree(temp_dir)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Using the CRDS system, update and download the necessary reference files for your dataset `jd0q14ctq`, including the flat and dark correction files. Ensure the environment variables are set properly for downloading with `crds`."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom acstools import crds\n\n# Set the environment variables\nos.environ['CRDS_SERVER_URL'] = 'https://hst-crds.stsci.edu'\nos.environ['CRDS_CONTEXT'] = 'hst_0992.pmap'\n\n# Get the reference file paths\ncrds_bestrefs = crds.getreferences({'INSTRUMENT': 'acs', 'DETECTOR': 'wfc'}, \n                                   reftypes=['DARKFILE', 'PFLTFILE'], \n                                   download=True)\nprint(crds_bestrefs)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Access the header of the `jd0q14ctq_flc.fits` file to extract the filenames of the flat, CTE-corrected dark, and superbias reference files. Prepare these filenames for further use."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom astropy.io import fits\n\nfilename = 'jd0q14ctq_flc.fits'\nwith fits.open(filename) as hdulist:\n    hdr = hdulist[0].header\n    flat_ref_file = hdr['PFLTFILE'].strip('uref$/').lower()\n    dark_ref_file = hdr['DRKCFILE'].strip('uref$/').lower()\n    bias_ref_file = hdr['BIASFILE'].strip('uref$/').lower()\n\nprint(\"Flat field reference file:\", flat_ref_file)\nprint(\"Dark CTE-corrected reference file:\", dark_ref_file)\nprint(\"Superbias reference file:\", bias_ref_file)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Open the reference flat file and retrieve the `SCI` extensions for both CCDs. This will be used later to understand its effects on the image."
            },
            {
                "type": "code",
                "text": "```python\n\n# Open the flat file to inspect the SCI extensions for both CCD chips\nwith fits.open(flat) as hdu_list:\n    flat_chip1 = hdu_list['SCI', 1].data\n    flat_chip2 = hdu_list['SCI', 2].data\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Open the dark correction file and extract the `SCI` extensions while ensuring negative pixel values are set to zero, as these may result from previous corrections."
            },
            {
                "type": "code",
                "text": "```python\n\ndark_hdu = fits.open('{}/{}'.format(os.environ['jref'], dkc))\n\n# Extract the SCI extensions for both CCDs, and set negative values to zero\ndark_wfc1 = dark_hdu[4].data.clip(min=0)\ndark_wfc2 = dark_hdu[1].data.clip(min=0)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Extract the `ERR` and `DQ` extensions from the superbias file for both CCDs, these will be useful for error correction and quality assessments in later steps."
            },
            {
                "type": "code",
                "text": "```python\n\nbias_hdu = fits.open('{}/{}'.format(os.environ['jref'], bias))\n\nerr_bias_wfc1 = bias_hdu[5].data\nerr_bias_wfc2 = bias_hdu[2].data\n\ndq_bias_wfc1 = bias_hdu[6].data\ndq_bias_wfc2 = bias_hdu[3].data\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If necessary, open the flash reference file and acquire the `SCI` extensions for both CCDs to account for potential post-flash corrections, as demonstrated in the commented lines."
            },
            {
                "type": "code",
                "text": "```python\n\n# Uncomment and use if flash file corrections are needed\n# flash_hdu = fits.open('{}/{}'.format(os.environ['jref'], flash))\n\n# flash_wfc1 = flash_hdu[4].data\n# flash_wfc2 = flash_hdu[1].data\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 3. Create image of artificial stars\nGenerate a tuple containing the dimensions of `jd0q14ctq_flc.fits` file's `SCI` extension for CCD chip WFC2."
            },
            {
                "type": "code",
                "text": "```python\n\nwith fits.open('jd0q14ctq_flc.fits') as flc_hdu:\n    sci_shape_wfc2 = flc_hdu['SCI', 2].data.shape\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Create a set of random Gaussian source parameters using the shape obtained earlier to specify the dimensions. Ensure that the number of sources, brightness range, and shape parameters adhere to those typical for a 47 Tuc field with a FWHM of about 2.5 pixels."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom photutils.datasets import make_100gaussians\nimport numpy as np\n\nn_sources = 100  # Number of sources\nfwhm = 2.5  # Full Width at Half Maximum in pixels\n\nmean_flux = 5000  # Average brightness\nstddev_flux = 1000  # Brightness variation\n\nsources = make_100gaussians(shape, n_sources=n_sources, fwhm=fwhm, mean=mean_flux, stddev=stddev_flux)\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Use the Gaussian source parameters you created to generate a synthetic image with Gaussian sources. Include Poisson noise to simulate real observational conditions."
            },
            {
                "type": "code",
                "text": "```python\n\nny, nx = shape  # dimensions from WFC2 of jd0q14ctq_flc.fits\n\nimage = models.Gaussian2D(sources['amplitude'], sources['x_mean'], sources['y_mean'],\n                          sources['x_stddev'], sources['y_stddev'], sources['theta'])\n\n# Generate several Gaussian spots\nsynthetic_image = np.zeros((ny, nx))\nfor i in range(n_sources):\n    y, x = np.ogrid[:ny, :nx]\n    synthetic_image += image[i](x, y)\n\n# Add Poisson noise\nnoisy_image = synthetic_image + np.random.poisson(lam=synthetic_image)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Visually represent the synthetic star field with a plot. Indicate the positions of the Gaussian sources as well."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom astropy.visualization import simple_norm\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nnorm = simple_norm(synth_stars_image, 'sqrt', percent=99.5)\nplt.imshow(synth_stars_image, norm=norm, cmap='viridis', origin='lower')\nplt.colorbar(label='Counts')\n\n# Plot the positions of the Gaussian sources\nplt.scatter(sources['x_mean'], sources['y_mean'], s=20, edgecolor='red', facecolor='none')\n\nplt.xlabel('X Pixel')\nplt.ylabel('Y Pixel')\nplt.title('Synthetic Star Field')\nplt.show()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### Option A: Start with an observed FLC image\nVisually inspect a portion of the `flc` image obtained from the `jd0q14ctq` dataset. Plot this part of the image to observe the presence of stars of various magnitudes and any cosmic rays."
            },
            {
                "type": "code",
                "text": "```python\n\nflc_image = fits.getdata('jd0q14ctq_flc.fits', ext=1)\n\n# Set the region to inspect, (x, y, width, height)\nx, y, width, height = 1000, 1000, 100, 100\n\nflc_region = flc_image[y:y+height, x:x+width]\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\nax.imshow(flc_region, cmap='gray', origin='lower', vmin=0, vmax=np.percentile(flc_region, 99))\nax.set_title('FLC Image Portion')\nax.set_xlabel('X Pixel')\nax.set_ylabel('Y Pixel')\nplt.show()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 4A. Add artificial stars\nAdd the image of artificial stars that was generated earlier to the `flc` image for both CCDs. Save this modified image to a new file."
            },
            {
                "type": "code",
                "text": "```python\n\n# Add artificial stars to the original FLC image in both CCDs\nflc_with_stars = flc.copy()  # Make a copy to preserve original data\n\nflc_with_stars += synth_stars_image\n\n# Write the modified image to a new FITS file\nhdu = fits.PrimaryHDU(data=flc_with_stars, header=fits.getheader('jd0q14ctq_flc.fits', ext=1))\nhdu.writeto('jd0q14ctq_flc_with_stars.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Visualize a section of the new `flc_stars` image, and encircle a few of the artificial stars placed in the image. This will help in identifying their positions in the image."
            },
            {
                "type": "code",
                "text": "```python\n\nflc_stars = fits.getdata('jd0q14ctq_stars_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flc_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 5A. Reverse the flat and dark correction\nCalculate the total exposure time of the image by considering the exposure and flash durations alongside an additional buffer time for the instrument's overheads."
            },
            {
                "type": "code",
                "text": "```python\n\nexpo_time = hdu[0].header['EXPTIME']\nflash_dur = hdu[0].header.get('FLASHDUR', 0.0)\nflash_curr = hdu[0].header.get('FLASHCUR', 0.0)\n\n# Calculate the instrument overhead by considering the time required to read out the CCD\n# and apply a correction factor to the exposure time for electronic overhead.\noverhead_time = 0.5  # An estimated overhead time in seconds\n\ntotal_exposure_time = expo_time + flash_dur + overhead_time\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Open the combined image and retrieve the `SCI` extensions. Multiply by the flat correction, then add the scaled dark current to account for the total exposure time, simulating observational noise. Save this modified image. Optionally, consider reversing the flash correction by adding Poisson noise from the flash file."
            },
            {
                "type": "code",
                "text": "```python\n\nscience_data_wfc1 = hdu[4].data\nscience_data_wfc2 = hdu[1].data\n\n# Reverse the flat correction\nscience_data_wfc1 *= flat_wfc1\nscience_data_wfc2 *= flat_wfc2\n\n# Add back the scaled dark current\nscience_data_wfc1 += dkc_wfc1 * darktime\nscience_data_wfc2 += dkc_wfc2 * darktime\n\n# Optionally reverse the flash correction\n# flash_wfc1_noisy = np.random.poisson(flash_wfc1 * flashtime)\n# flash_wfc2_noisy = np.random.poisson(flash_wfc2 * flashtime)\n# science_data_wfc1 += flash_wfc1_noisy\n# science_data_wfc2 += flash_wfc2_noisy\n\n# Write the new file with reversed corrections\nhdu.writeto('jd0q14ctq_reversed_flc.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Update the header of the resultant file to ensure it is marked appropriately for the subsequent forward model processing."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu[0].header['FLSHFILE'] = 'N/A'\nhdu[0].header['DCHI_COR'] = 'PERFORM'\n\nhdu.writeto('jd0q14ctq_stars_pfl_dkc.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 6A. Run CTE forward model\nRun the Charge Transfer Efficiency (CTE) forward model simulation on the processed image file that includes artificial stars and has had flat and dark corrections scaled back. After the simulation, rename the output file to prepare it for further CALACS processing."
            },
            {
                "type": "code",
                "text": "```python\n\ncteflag = acstools.cteflag.CteFlag()\n\noutput_file = 'jd0q14ctq_stars_pfl_dkc_fwd.fits'\ncteflag.run(input_file='jd0q14ctq_stars_pfl_dkc.fits', output_file=output_file, \n            directory='./', cte_dir='')\n\n# Rename the file for the next processing steps\nos.rename(output_file, 'jd0q14ctq_stars_fwd.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Access the header and `SCI` (science data) and `ERR` (error data) extensions of the image file that has been forward modeled. Prepare to update the `ERR` extensions by calculating new error values based on the science data after accounting for forward model misalignments."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\nsci_wfc1 = hdu[4].data\nsci_wfc2 = hdu[1].data\n\nerr_wfc1 = hdu[5].data\nerr_wfc2 = hdu[2].data\n\nhdr = hdu[0].header\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Retrieve the read noise and gain values for each detector quadrant from the image header. You will use these values to calculate accurate error estimates for the forward-modeled data."
            },
            {
                "type": "code",
                "text": "```python\n\nrn_A = hdr['READNSEA']\nrn_B = hdr['READNSEB']\nrn_C = hdr['READNSEC']\nrn_D = hdr['READNSED']\n\ngain_A = hdr['ATODGNA']\ngain_B = hdr['ATODGNB']\ngain_C = hdr['ATODGNC']\ngain_D = hdr['ATODGND']\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Set all negative pixel values to zero for the `SCI` extensions of the forward-modeled image. Compute the appropriate error for each quadrant, updated with the read noise and gain, and store these recalculated errors in the `ERR` extensions. Save the modified image data."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1[sci_wfc1 < 0.] = 0.\nsci_wfc2[sci_wfc2 < 0.] = 0.\n\n# Define the error calculation function\ndef calculate_err(sci_data, rn, gain):\n    err_data = np.sqrt(sci_data + (rn / gain)**2)\n    return err_data\n\n# Calculate errors for each section\nerr_wfc1_Q1 = calculate_err(sci_wfc1[:2048, :2048], rn_A, gain_A)\nerr_wfc1_Q2 = calculate_err(sci_wfc1[:2048, 2048:], rn_B, gain_B)\nerr_wfc1_Q3 = calculate_err(sci_wfc1[2048:, :2048], rn_C, gain_C)\nerr_wfc1_Q4 = calculate_err(sci_wfc1[2048:, 2048:], rn_D, gain_D)\n\nerr_wfc2_Q1 = calculate_err(sci_wfc2[:2048, :2048], rn_A, gain_A)\nerr_wfc2_Q2 = calculate_err(sci_wfc2[:2048, 2048:], rn_B, gain_B)\nerr_wfc2_Q3 = calculate_err(sci_wfc2[2048:, :2048], rn_C, gain_C)\nerr_wfc2_Q4 = calculate_err(sci_wfc2[2048:, 2048:], rn_D, gain_D)\n\n# Re-assign errors into ERR extensions\nerr_wfc1[:2048, :2048] = err_wfc1_Q1\nerr_wfc1[:2048, 2048:] = err_wfc1_Q2\nerr_wfc1[2048:, :2048] = err_wfc1_Q3\nerr_wfc1[2048:, 2048:] = err_wfc1_Q4\n\nerr_wfc2[:2048, :2048] = err_wfc2_Q1\nerr_wfc2[:2048, 2048:] = err_wfc2_Q2\nerr_wfc2[2048:, :2048] = err_wfc2_Q3\nerr_wfc2[2048:, 2048:] = err_wfc2_Q4\n\nhdu[5].data = err_wfc1\nhdu[2].data = err_wfc2\n\nhdu.writeto('jd0q14ctq_stars_ctefmod_blv_err.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### (Optional) 7A. Run CTE correction\nAdjust the `PCTECORR` and `NEXTEND` keywords in the header of the forward-modeled image file. Then, execute the CTE correction process on this image using the provided instrument tools."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'PCTECORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'NEXTEND', value=6)\n\ncalacs.e('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 8A. Apply flat and dark correction\nSet the `DARKCORR` and `FLATCORR` keywords to `PERFORM` in the header of the forward-modeled image to enable the flat-field and dark correction process using the relevant tools. Optionally, if the data included a flash, also set the `FLSHCORR` keyword accordingly as shown in the commented instruction."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('jd0q14ctq_stars_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "In case the forward-modeled image underwent CTE correction, repeat the flat-field and dark correction as in the previous step on the CTE-corrected image to produce the final `flc`-like image."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('jd0q14ctq_stars_ctefmod_blc_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('jd0q14ctq_stars_ctefmod_blc_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('jd0q14ctq_stars_ctefmod_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('jd0q14ctq_stars_ctefmod_blc_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Generate a visualization of a specific region from the final `flt` image. Highlight the positions of the injected artificial stars using a distinct marker."
            },
            {
                "type": "code",
                "text": "```python\n\nflt_stars = fits.getdata('jd0q14ctq_stars_ctefmod_flt.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flt_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Visualize the same specific region from the `flc` image if it was generated, while highlighting the positions of the artificial stars with appropriate markers."
            },
            {
                "type": "code",
                "text": "```python\n\nflc_stars = fits.getdata('jd0q14ctq_stars_ctefmod_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(flc_stars, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### Option B: Start with a synthetic image\nExecute the necessary tool on your synthetic `raw` file to prepare a temporary file that consists of the essential data extensions. This initial step is crucial for ensuring that the subsequent CTE forward modeling process runs smoothly by setting up error and data quality extensions."
            },
            {
                "type": "code",
                "text": "```python\n\nacsccd.acsccd('jd0q14ctq_raw.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Access the prepared temporary file and initialize its `SCI` extensions to zero across their full dimensions. This step essentially sets the stage for substituting real observational data with a comprehensive synthetic dataset of astronomical sources and noise."
            },
            {
                "type": "code",
                "text": "```python\n\nwith fits.open('jd0q14ctq_blv_tmp.fits', mode='update') as hdu:\n    for ext in [1, 4]:  # SCI extensions for both WFC CCDs\n        hdu[ext].data[:, :] = 0\n    hdu.flush()  # Ensure changes are written\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Generate a synthetic noise image with a defined sky background level and integrate it into your synthetic dataset. Consider adding the artificial stars as well to construct a full synthetic scene for analysis."
            },
            {
                "type": "code",
                "text": "```python\n\nsky_background = 20  # Example sky background level\nsynth_noise_image = np.random.poisson(sky_background, size=shape)\n\n# Combine noise with artificial stars\nsynth_wfc1 = synth_stars_image + synth_noise_image\nsynth_wfc2 = synth_stars_image + synth_noise_image\n\nwfc1[:] = synth_wfc1\nwfc2[:] = synth_wfc2\n\nhdu.writeto('jd0q14ctq_synth_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Prepare to visualize a section of the synthetic image. Highlight the synthetic sources to ensure they are readily identifiable for further examination."
            },
            {
                "type": "code",
                "text": "```python\n\nsynth = fits.getdata('synth.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "To accommodate the removal of dark current after executing the forward model, modify the header of your synthetic image to reflect your chosen exposure and flash durations. These adjustments to the `EXPTIME` and `FLASHDUR` keywords mimic realistic observational conditions."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth.fits', 'EXPTIME', value=1000)\nfits.setval('synth.fits', 'FLASHDUR', value=10)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Make sure to revise the dark time header keyword in the synthetic image, excluding the overhead in this initial step. This update is vital for downstream processes that rely on proper dark current calculations."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth.fits', 'DARKTIME', value=exptime + flashdur)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "For your synthetic data, integrate calibration adjustments, such as flat-field application and adding Poisson-sampled dark noise, to mimic real observational conditions. Save this newly calibrated data, ensuring it's set for further CTE analysis."
            },
            {
                "type": "code",
                "text": "```python\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 *= flat_wfc1\nwfc2 *= flat_wfc2\n\nwfc1 += np.random.poisson(dkc_wfc1*darktime)\nwfc2 += np.random.poisson(dkc_wfc2*darktime)\n\n# wfc1 += np.random.poisson(flash_wfc1*flashdur)\n# wfc2 += np.random.poisson(flash_wfc2*flashdur)\n\nhdu.writeto('synth_blc_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 5B. Run CTE forward model\nRun the Charge Transfer Efficiency (CTE) forward model on the synthetic `blc_tmp` image file, simulating the readout of the detector and the impact of pixel-based charge transfer losses. Once complete, rename the output to ensure proper handling by subsequent processes."
            },
            {
                "type": "code",
                "text": "```python\n\nacscteforwardmodel.acscteforwardmodel('synth_blc_tmp.fits')\n\nos.rename('synth_blc_tmp_ctefmod.fits', 'synth_ctefmod_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Create normally distributed noise images for each quadrant of the Forward-Modeled Synthetic Image based on the read noise values found in the header. Concatenate the quadrants appropriately, and add the resulting noise to the forward-modeled image."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_blv_tmp.fits')\n\nread_noise_A = np.random.randn(2068, 2048) * rn_A\nread_noise_B = np.random.randn(2068, 2048) * rn_B\nread_noise_C = np.random.randn(2072, 2048) * rn_C\nread_noise_D = np.random.randn(2072, 2048) * rn_D\n\nsci_wfc1 = hdu[4].data + np.hstack((read_noise_A, read_noise_B))\nsci_wfc2 = hdu[1].data + np.hstack((read_noise_C, read_noise_D))\n\nhdu.writeto('synth_ctefmod_blv_tmp_noisy.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_blv_tmp.fits')\n\nwfc1 = hdu[4].data\nwfc2 = hdu[1].data\n\nwfc1 += wfc1_rn\nwfc2 += wfc2_rn\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Access the header and calculate the error extensions for the forward-modeled synthetic image based on the readnoise, the SCI data, and the superbias error. Ensure to set all negative pixel values in the SCI extensions to zero before calculating the new error values. Save these updated error extensions back into the file."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_rn_blv_tmp.fits')\n\nsci_wfc1 = hdu[4].data\nsci_wfc2 = hdu[1].data\n\nerr_wfc1 = hdu[5].data\nerr_wfc2 = hdu[2].data\n\nhdr = hdu[0].header\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Extract read noise and gain values for each CCD quadrant from the image headers. Implement them in the calculation of new error values for each pixel in the `ERR` extensions, derived from the scientific data, read noise, and superbias errors."
            },
            {
                "type": "code",
                "text": "```python\n\nrn_A = hdr['READNSEA']\nrn_B = hdr['READNSEB']\nrn_C = hdr['READNSEC']\nrn_D = hdr['READNSED']\n\ngain_A = hdr['ATODGNA']\ngain_B = hdr['ATODGNB']\ngain_C = hdr['ATODGNC']\ngain_D = hdr['ATODGND']\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Calculate and store the updated error values for each CCD quadrant using read noise and gain, ensuring proper setting of negative pixel values to zero in the SCI extensions. Save the recalculated error back into the image file."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1_pos = np.copy(sci_wfc1)\nsci_wfc2_pos = np.copy(sci_wfc2)\n\nsci_wfc1_pos[sci_wfc1_pos < 0] = 0\nsci_wfc2_pos[sci_wfc2_pos < 0] = 0\n\n# The superbias ERR arrays contain 20 rows of virtual overscan at the edge of \n# each CCD furthest from the amplifier and 24 columns of physical prescan on the\n# left and right edges.\nerr_A = np.sqrt(sci_wfc1_pos[:, :2048] + rn_A**2 + (err_bias_wfc1[20:, 24:2072]*gain_A)**2)\nerr_B = np.sqrt(sci_wfc1_pos[:, 2048:] + rn_B**2 + (err_bias_wfc1[20:, 2072:-24]*gain_B)**2)\nerr_C = np.sqrt(sci_wfc2_pos[:, :2048] + rn_C**2 + (err_bias_wfc2[:-20, 24:2072]*gain_C)**2)\nerr_D = np.sqrt(sci_wfc2_pos[:, 2048:] + rn_D**2 + (err_bias_wfc2[:-20, 2072:-24]*gain_D)**2)\n\nerr_wfc1[:] = np.hstack((err_A, err_B))\nerr_wfc2[:] = np.hstack((err_C, err_D))\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Prepare for updating the data quality (DQ) extensions by modifying header keywords for `DQICORR` and `SINKCORR`. Rename the synthetic image appropriately, and thereafter process it using `acsccd`, ensuring to incorporate DQ corrections and add extensions from the appropriate superbias."
            },
            {
                "type": "code",
                "text": "```python\n\nos.system('calacs.e --version')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Rename the forward-modeled synthetic file, set the `DQICORR` and `SINKCORR` keywords to perform corrections, and process the renamed `raw` image to update the DQ extensions based on the superbias file using `acsccd`."
            },
            {
                "type": "code",
                "text": "```python\n\nos.rename('synth_ctefmod_rn_blv_tmp.fits', 'synth_ctefmod_rn_raw.fits')\n\nfits.setval('synth_ctefmod_rn_raw.fits', 'DQICORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_raw.fits', 'SINKCORR', value='PERFORM')\n\nacsccd.acsccd('synth_ctefmod_rn_raw.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Access and obtain the data quality extensions of the synthetic image and the superbias file, combining them with a bitwise OR operation for accurate DQ marking in the synthetic image."
            },
            {
                "type": "code",
                "text": "```python\n\nhdu = fits.open('synth_ctefmod_rn_blv_tmp.fits')\ndq_wfc1 = hdu[6].data\ndq_wfc2 = hdu[3].data\n\nsuperbias_dq_wfc1 = dq_bias_wfc1[20:, 24:-24]\nsuperbias_dq_wfc2 = dq_bias_wfc2[:-20, 24:-24]\n\ndq_wfc1 = np.bitwise_or(dq_wfc1, superbias_dq_wfc1)\ndq_wfc2 = np.bitwise_or(dq_wfc2, superbias_dq_wfc2)\n\nhdu.writeto('synth_ctefmod_dq_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Divide the science and error extensions by their respective gain values to reverse the conversion to electrons applied by the `acsccd` process, as your model initially defined the data in electrons. Save this corrected dataset."
            },
            {
                "type": "code",
                "text": "```python\n\nsci_wfc1 /= np.array([gain_A, gain_B], dtype=float).reshape(1, -1)\nsci_wfc2 /= np.array([gain_C, gain_D], dtype=float).reshape(1, -1)\n\nerr_wfc1 /= np.array([gain_A, gain_B], dtype=float).reshape(1, -1)\nerr_wfc2 /= np.array([gain_C, gain_D], dtype=float).reshape(1, -1)\n\nhdu.writeto('synth_ctefmod_rn_blv_tmp.fits', overwrite=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 6B. (Optional) Run CTE correction\nPrepare the synthetic forward-modeled image for Charge Transfer Efficiency (CTE) correction by setting the `PCTECORR` keyword to `PERFORM`. Then, apply the CTE correction procedure using the relevant astronomical tools designed for this purpose. Save the resulting file with the `_blc_tmp.fits` extension to indicate it has undergone standard calibration."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'PCTECORR', value='PERFORM')\n\nacscte.acscte('synth_ctefmod_rn_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### 7B. Apply flat and dark correction\nCompile the final `flt`-like image by running the flat-field and dark corrections on the forward-modeled synthetic image. Make sure that the relevant header keywords for `DARKCORR`, `FLATCORR`, and `FLSHCORR` are set to `PERFORM`. This will finalize the image for further scientific analysis."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_blv_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('synth_ctefmod_rn_blv_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('synth_ctefmod_rn_blv_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If the synthetic image underwent CTE correction in the process, run the flat-field and dark corrections again on the CTE-corrected image to produce the final `flc`-like image."
            },
            {
                "type": "code",
                "text": "```python\n\nfits.setval('synth_ctefmod_rn_blc_tmp.fits', 'DARKCORR', value='PERFORM')\nfits.setval('synth_ctefmod_rn_blc_tmp.fits', 'FLATCORR', value='PERFORM')\n# fits.setval('synth_ctefmod_rn_blc_tmp.fits', 'FLSHCORR', value='PERFORM')\n\nacs2d.acs2d('synth_ctefmod_rn_blc_tmp.fits')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Visualize a specific section of the final `flt`-like image, ensuring to mark the position of the artificial stars for reference and accuracy checks."
            },
            {
                "type": "code",
                "text": "```python\n\nsynth_ctefmod = fits.getdata('synth_ctefmod_rn_flt.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth_ctefmod, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "If you have also produced an `flc`-like corrected image, visualize the same section of this `flc` image and mark the artificial stars similarly for consistency in your analysis."
            },
            {
                "type": "code",
                "text": "```python\n\nsynth_ctefmod_flc = fits.getdata('synth_ctefmod_rn_flc.fits', ext=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(9, 4))\n\nax.imshow(synth_ctefmod_flc, vmin=0, vmax=200, interpolation='nearest', cmap='Greys_r', \n          origin='lower')\nax.plot(sources['x_mean'], sources['y_mean'], marker='o', markersize=20, \n        markerfacecolor='none', markeredgecolor='red', linestyle='none')\n\nax.set_xlim(2000, 2800)\nax.set_ylim(800, 1300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### For more help:\n\nMore details may be found on the [ACS website](http://www.stsci.edu/hst/instrumentation/acs) and in the [ACS Instrument](https://hst-docs.stsci.edu/display/ACSIHB) and [Data Handbooks](http://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/acs/documentation/other-documents/_documents/acs_dhb.pdf).\n\nPlease visit the [HST Help Desk](http://hsthelp.stsci.edu). Through the help desk portal, you can explore the HST Knowledge Base and request additional help from experts."
            },
            {
                "type": "markdown",
                "text": "### About this Notebook\nThank you for reviewing this notebook. Please ensure to acknowledge Jenna Ryon, ACS Instrument Team, if you build upon or share any content from this notebook for your own purposes. \n\nFor any clarifications, additional support, or suggestions on this notebook, please reach out to the [HST Help Desk](http://hsthelp.stsci.edu).\n\nTo go back to the initial section, please follow the [Top of Page](#title_ID).\n\nEnjoy your exploration of the universe!"
            },
            {
                "type": "code",
                "text": "```python\n\n\n\n```",
                "output": ""
            }
        ],
        "alignments": [
            {
                "matching": [
                    0,
                    0
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    1,
                    1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    2,
                    2
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    3,
                    3
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    4,
                    4
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    5,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    6,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    7,
                    5
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    8,
                    6
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    9,
                    7
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    10,
                    8
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    11,
                    9
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    12,
                    10
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    13,
                    11
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    14,
                    12
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    13
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    15,
                    14
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    15
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    16,
                    16
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    17
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    17,
                    18
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    18,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    19,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    20,
                    19
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    21,
                    20
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    21
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    22,
                    22
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    23,
                    23
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    24,
                    24
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    25
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    25,
                    26
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    26,
                    27
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    27,
                    28
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    28,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    29,
                    29
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    30,
                    30
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    31,
                    31
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    32,
                    32
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    33,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    34,
                    33
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    35,
                    34
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    36,
                    35
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    37,
                    36
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    38,
                    37
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    39,
                    38
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    40,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    42,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    39
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    43,
                    40
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    44,
                    41
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    45,
                    42
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    46,
                    43
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    47,
                    44
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    48,
                    45
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    49,
                    46
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    50,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    51,
                    47
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    52,
                    48
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    53,
                    49
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    54,
                    50
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    55,
                    51
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    56,
                    52
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    57,
                    53
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    58,
                    54
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    55
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    59,
                    56
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    60,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    61,
                    57
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    62,
                    58
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    63,
                    59
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    64,
                    60
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    65,
                    61
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    66,
                    62
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    67,
                    63
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    68,
                    64
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    69,
                    65
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    70,
                    66
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    71,
                    67
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    72,
                    68
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    73,
                    69
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    74,
                    70
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    75,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    76,
                    71
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    77,
                    72
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    78,
                    73
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    79,
                    74
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    80,
                    75
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    81,
                    76
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    82,
                    77
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    83,
                    78
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    84,
                    79
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    85,
                    80
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    86,
                    81
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    87,
                    82
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    88,
                    83
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    89,
                    84
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    90,
                    85
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    91,
                    86
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    92,
                    87
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    93,
                    88
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    94,
                    89
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    95,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    96,
                    90
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    97,
                    91
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    98,
                    92
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    99,
                    93
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    100,
                    94
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    101,
                    95
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    102,
                    96
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    103,
                    97
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    98
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    104,
                    99
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    105,
                    100
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    106,
                    101
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    107,
                    102
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            }
        ]
    },
    {
        "title": "CalCOS_assignment_colloquial_gpt-4o",
        "source": [
            {
                "type": "markdown",
                "text": "<a id=\"topC\"></a>\n\n# Running the COS Data Pipeline (`CalCOS`)\n\n# Learning Goals:\n<font size=\"4 \"> This Notebook is designed to walk the user (<em>you</em>) through:</font>\n\n**1. [Setting up the Environment to Run `CalCOS`](#setupC)**\n\n\\- 1.1. [Prerequisites](#prereqC)\n\n\\- 1.2. [Create Your `conda` Environment](#condaenvC)\n\n\\- 1.3. [Imports and Basic Directories](#impdirC)\n\n\\- 1.4. [Setup a Reference File directory](#lrefC)\n\n\n**2. [Gathering the Data to Run `CalCOS`](#gatherC)**\n\n\\- 2.1. [Downloading the Raw Data](#datadlC)\n\n\\- 2.2. [Gathering Reference Files](#reffileC)\n\n**3. [Processing Raw COS data using `CalCOS`](#runC)**\n\n\\- 3.1. [Running `CalCOS`: *From a `Python` Environment*](#runpyC)\n\n\\- 3.2. [Running `CalCOS`: *From the Command Line*](#runcliC)\n\n**4. [Re-processing COS Data with Altered Parameters](#rerunC)**\n\n\\- 4.1. [Altering the Calibration Switches](#alterswitchC)\n\n\\- 4.2. [Running `CalCOS` with a Specific Set of Switches](#switchrunC)\n\n\\- 4.3. [Running `CalCOS` with a Different Reference File](#refrunC)\n"
            },
            {
                "type": "markdown",
                "text": "# 0. Introduction\n**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n\n**`CalCOS`** is the data processing pipeline which converts the raw data produced by COS's detectors onboard HST into usable spectral data. It transforms the data from a list of many individual recorded photon interactions into tables of wavelength and flux. \n\n**This tutorial aims to prepare you run the `CalCOS` pipeline to reduce spectral data taken with the COS instrument.** It focuses on COS data taken in `TIME-TAG` mode. \n*Note* that there is another, less commonly used mode, `ACCUM`, which should generally be used only for UV bright targets.\n\n- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/)."
            },
            {
                "type": "markdown",
                "text": "#### Notes for those new to Python/Jupyter/Coding:\n- You will frequently see exclamation points (**!**) or dollar signs (**\\$**) at the beginning of a line of code. These are not part of the actual commands. The exclamation points tell a Jupyter Notebook cell to pass the following line to the command line, and the dollar sign merely indicates the start of a terminal prompt. "
            },
            {
                "type": "markdown",
                "text": "<a id = setupC></a>\n# 1. Setting up the Environment to Run `CalCOS`\n\nThe first step to processing your data is setting up an environment from which to run `CalCOS`.\n<a id = prereqC></a>\n## 1.1. Prerequisites\nThis tutorial assumes some basic knowledge of the command line and was built using a unix style shell. Those using a Windows computer will likely have the best results if working within the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\n\nIf you do not already have any distribution of the `conda` tool, see [this page](https://stenv.readthedocs.io/en/latest/getting_started.html#getting-started) for instructions, and install either [`anaconda` (\\~ 3 GB, more beginner friendly, lots of extras you likely won't use)](https://docs.anaconda.com/anaconda/install/), [`miniconda` (\\~ 400 MB, only what you need to make environments)](https://docs.conda.io/en/latest/miniconda.html), or [`mamba` (\\~85 MB, similar to `miniconda` but rewritten in C++).](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html)\n"
            },
            {
                "type": "markdown",
                "text": "\n<a id = condaenvC></a>\n## 1.2. Create Your `conda` Environment\n\nOnce you have `conda` installed, you can create an environment. \n\nOpen up your terminal app, likely `Terminal` or `iTerm` on a Mac or `Windows Terminal` or `Powershell` on Windows.\n\nFirst, add the `conda-forge` channel to your computer's `conda` channel list. This enables `conda` to look in the right place to find all the packages we want to install.\n\n``` $ conda config --add channels conda-forge ```\n\nNow we can create a new environment for running `CalCOS`; let's call it `calcos_env`, and initialize it with `Python` version 3.10 and several packages we'll need.\n\n``` $ conda create -n calcos_env python=3.10 notebook jupyterlab numpy astropy matplotlib astroquery```\n\nAfter allowing conda to proceed to installing the packages (type `y` then hit enter), you can see all of your environments with:\n\n``` $ conda env list```\n\nand then switch over to your new environment with:\n\n``` $ conda activate calcos_env ```\n\nFinally you must install the `CalCOS` and `CRDS` packages using `pip`:\n\n``` $ pip install calcos crds```\n\nAt this point, typing `calcos --version` into the command line and hitting enter should no longer yield the error: \n\n```command not found: calcos``` \n\nbut rather respond with a version number, i.e. version `3.4.4` at the time of writing this Notebook."
            },
            {
                "type": "markdown",
                "text": "At this point, if you started this Jupyter Notebook in another `Python` environment, you should now quit that instance, run `$ conda activate calcos_env`, and reopen this Jupyter Notebook. If you're unsure whether you're already using the `calcos_env` environment, you can see the active environment with the following cell:"
            },
            {
                "type": "code",
                "text": "```python\n\n# Displays name of current conda environment\nfrom os import environ, system\nif \"CONDA_DEFAULT_ENV\" in environ:\n    print(\"You are using:\", environ[\"CONDA_DEFAULT_ENV\"])\nelse:\n    system(\"conda info --envs\")\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id=impdirC></a>\n\n## 1.3. Imports and Basic Directories\n\nWe will import the following packages:\n\n- `calcos` to run the COS data pipeline\n- `astroquery.mast Mast and Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n- `numpy` to handle array functions (version $\\ge$ 1.17)\n- `astropy.io fits` for accessing FITS files\n- `astropy.table Table` for creating and reading organized tables of the data\n- `matplotlib.pyplot` for plotting data\n- `glob`, `shutil`, and `os` for searching and working with system files and variables\n- `pathlib Path` for managing system paths"
            },
            {
                "type": "code",
                "text": "```python\n\nimport calcos\nimport numpy as np\nfrom astropy.io import fits\nfrom astropy.table import Table\nimport matplotlib.pyplot as plt\nfrom astroquery.mast import Observations\nimport glob\nimport os\nimport shutil\nfrom pathlib import Path\n\n# This line makes plots appear in the Notebook instead of a separate window\n%matplotlib inline\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### We will also define a few basic directories in which to place our inputs and outputs."
            },
            {
                "type": "code",
                "text": "```python\n\n# These will be important directories for the Notebook\ndatadir = Path('./data/')\noutputdir = Path('./output/')\n\n# Make the directories if they don't exist\ndatadir.mkdir(exist_ok=True)\noutputdir.mkdir(exist_ok=True)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = lrefC></a>\n## 1.4. Set up a Reference File Directory\n\n`CalCOS` needs to be able to find all your reference files, (flat field image, bad pixel table, etc.), and the best way to enable that is to create a central directory of all the calibration files you'll need. We refer to this directory  as `lref` by convention, and set a system variable `lref` to the location of the directory. In this section, we will create the `lref` environment variable; however, we need to populate the `lref` folder with the actual reference files. We do this in [Section 2.2](#reffileC). If you have already downloaded the set of COS reference files you need to use into an existing lref directory, you should instead set `lref` to the path to this directory. \n\nWe can assign a system variable in three different ways, depending on whether we are working from:\n1. The command line\n2. A `Python` environment\n3. A Jupyter Notebook\n\n|Unix-style Command Line| `Python` | Jupyter Notebook|\n|-|-|-|\n| export lref='./data/reference/...' | os.environ[\"lref\"] = \"./data/reference/...\"| %env lref ./data/reference/...|\n\n\nNote that this system variable must be set again with every new instance of a terminal - if you frequently need to use the same `lref` directory, consider adding an export statement to your `.bash_profile` or equivalent file.\n\nBecause this is a Jupyter Notebook, we set our reference directory with the [cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) below:\n\n<!-- Looking in the headers of our data below, we see that the `$lref` argument appears at the beginning of all of the reference file locations: -->"
            },
            {
                "type": "code",
                "text": "```python\n\n%env lref ./data/reference/references/hst/cos/\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We can note the value of the system variable using the following command:"
            },
            {
                "type": "code",
                "text": "```python\n\nos.getenv('lref')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "---\n\n<a id = gatherC></a>\n# 2. Gathering the Data to Run `CalCOS`\n\nThe `CalCOS` pipeline can be run either from a `Python` environment, or directly from a Unix-style command line. The two use the same underlying machinery but can differ in syntax. For specifics on the keywords to run `CalCOS` with specific behaviors and arguments, see [Table 3.2: Arguments for Running CalCOS in Python](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration#:~:text=Table%203.2%3A%20Arguments%20for%20Running%20calcos%20in%20Python) and [Table 3.3: Command-line Options for Running CalCOS in Unix/Linux/Mac](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration#:~:text=Table%203.3%3A%20Command%2Dline%20Options%20for%20Running%20calcos%20in%20Unix/Linux/Mac.).\n\n<a id = datadlC></a>\n## 2.1. Downloading the Raw Data\n\nFirst, we need to make sure we have all of our data ready and in the right spot. If you are unfamiliar with searching the archive for data, we recommend that you view our [tutorial on downloading COS data](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/DataDl/DataDl.ipynb). This Notebook will largely gloss over downloading the data.\n\nTo run `CalCOS`, we will need the following files:\n1. All the **raw data** from separate exposures we wish to combine as `_rawtag` FITS files\n2. The **association** file telling `CalCOS` which files to combine as a `_asn` FITS file.\n\n***Note* that we do not generally run the `CalCOS` pipeline directly on the data files, but instead on an association `_asn` file. This allows for the calibration of related exposures into combined `_x1dsum` files.**\n\nIf you instead use `_rawtag` or `_corrtag` exposure files as your inputs, you will only receive the exposure-specific `_x1d` files as your outputs.\n\nFor this example, we're choosing the dataset `LCXV13040` of COS/FUV observing the [quasar 3C48](http://simbad.cds.unistra.fr/simbad/sim-basic?Ident=3C+48&submit=SIMBAD+search). In the cell below we download the data from the archive:"
            },
            {
                "type": "code",
                "text": "```python\n\n# Query the MAST archive for data with observation id starting with lcxv1304\nq1 = Observations.query_criteria(\n                        obs_id='lcxv1304*')\n\n# Make a list of all products we could download with this file\npl = Observations.get_product_list(q1)\n\n# Filter to a list of only the products which are association files (asn)\nasn_file_list = pl[pl[\"productSubGroupDescription\"] == 'ASN']\n\n# Filter to a list of only therawtag files for both segments\nrawtag_list = pl[\n    (pl[\"productSubGroupDescription\"] == 'RAWTAG_A') |\n    (pl[\"productSubGroupDescription\"] == 'RAWTAG_B')\n]\n\n# Download the rawtag and asn lists to the data directory\nrawtag_locs = Observations.download_products(\n                                rawtag_list,\n                                download_dir=str(datadir))\n\nasn_locs = Observations.download_products(\n                                asn_file_list,\n                                download_dir=str(datadir))\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**By default, each exposure's files are downloaded to separate directories, as is the association file.**\n\nWe need to move around these files to all be in the same directory, which we do below."
            },
            {
                "type": "code",
                "text": "```python\n\nfor lpath in rawtag_locs['Local Path']:\n    Path(lpath).replace(datadir/os.path.basename(lpath))\n\nfor lpath in asn_locs['Local Path']:\n    Path(lpath).replace(datadir/os.path.basename(lpath))\n    asn_name = os.path.basename(lpath)\n\n# Delete the now-empty nested subdirectories (./data/mastDownload)\nshutil.rmtree(datadir/'mastDownload')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = reffileC></a>\n## 2.2. Gathering Reference Files\n\nThe following process of gathering reference files is given a detailed explanation in Section 3 of our [Notebook on setting up an environment to work with COS data](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb). Your process will be somewhat simpler and quicker if you have already downloaded the reference files.\n\nEach data file has an associated set of calibration files which are needed to run the associated correction with (i.e. you need the `FLATFILE` to flat field correct the data). These reference files must be located in the `$lref` directory to run the pipeline.\n\nThe STScI team is regularly producing new calibration files in an effort to keep improving data reduction. Periodically the pipeline is re-run on all COS data.\nTo determine which reference files were used most recently by STScI to calibrate your data, you can refer to your data file's `CRDS_CTX` keyword in its FITS header:"
            },
            {
                "type": "code",
                "text": "```python\n\n# Find all of the raw files:\nrawfiles = glob.glob(str(datadir/'*raw*.fits'))\n\n# Get the header of the 0th raw file, look for its CRDS context keyword:\ncrds_ctx = fits.getheader(rawfiles[0])['CRDS_CTX']\n\n# Print the file's CRDS context keyword:\nprint(f\"The CRDS Context last run with {rawfiles[0]} was:\\t{crds_ctx}\")\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "The value of this keyword in the header is a `.pmap` or observatory context file which tells the CRDS calibration data distribution program which files to distribute. You can also find the newest \"operational\" context on the [HST CRDS website](https://hst-crds.stsci.edu).\n\nTo download the reference files specified by a context file, we use the `crds` tool we installed earlier. "
            },
            {
                "type": "markdown",
                "text": "---\n**If you haven't already downloaded up-to-date reference files,** (as in Section 3 of [Setup Notebook](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb), [click to skip this cell and begin downloading the files!](#skipcellC)\n\n**If you have recently downloaded COS reference files,** (i.e. if you ran Section 3 of the [Setup Notebook](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb),) you likely do not have to download more reference files. Instead, follow the instructions in this cell and then skip to [Section 3](#runC).\n\nIf you already downloaded the files, you can simply point the pipeline to the ones you downloaded, using the `crds bestrefs` command, as shown in the following three steps. Run these steps from your command line if you already have the reference files in a local cache. *Note* also that there may be newer reference files available. To make sure you are always using the most up-to-date reference files, we advise you familiarize yourself with the newest files and documentation at the [CRDS homepage](https://hst-crds.stsci.edu).\n\n1. The following sets the environment variable for crds to look for the reference data online:\n\n```$ export CRDS_SERVER_URL=https://hst-crds.stsci.edu``` \n\n2. The following tells crds where to save the files it downloads - set this to the directory where you saved the crds_cache, i.e. in Section 3 of our Notebook on [Setup](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/Setup/Setup.ipynb):\n\n```$ export CRDS_PATH=${HOME}/crds_cache```\n\n3. The following will update the data files you downloaded so that they will be processed with the reference files you previously downloaded:\n\n```$ crds bestrefs --files data/*raw*.fits --update-bestrefs --new-context '<the imap or pmap file you used to download the reference files>'```\n\n\n**Assuming everything ran successfully, you can now [skip to Section 3](#runC).**\n\n---"
            },
            {
                "type": "markdown",
                "text": "<a id=skipcellC></a>\n\n<font size=\"4 \"> If you have not yet downloaded the reference files, you will need to do so, as shown below:</font>\n\n<font size=\"4 \">Caution!</font>\n    \n<img src= ./figures/warning.png width =\"60\" title=\"CAUTION!\" alt=\"A warning symbol. Watch out!\"> \n\n*Note* that as of the time of this Notebook's update, the pipeline context used below was **`hst_1071.pmap`**, but this changes over time. You are running this in the future, and there is certainly a newer context you would be better off working with. Take a minute to consider this, and check the [HST Calibration Reference Data System webpage](http://hst-crds.stsci.edu/) to determine what the **current operational pmap file** is. "
            },
            {
                "type": "markdown",
                "text": "Unless we are connected to the STScI network, or already have the reference files on our machine, we will need to download the reference files and tell the pipeline where to look for the flat files, bad-pixel files, etc.\n\nThe process in the following two cells can take a long time and strain network resources. If you have already downloaded up-to-date COS reference files, we recommend that you avoid doing so again. Instead, keep these `crds` files in an accessible location, and point an environment variable `lref` to this directory. For instance, if your `lref` files are on your home directory in a subdirectory called `crds_cache`, give Jupyter the following command:\n\n```%env lref /Users/<your username>/crds_cache/references/hst/cos/```\n\nIf you have an older cache of reference files, you may also simply update your cached reference files. Please see the [CRDS Guide](https://hst-crds.stsci.edu/static/users_guide/index.html) for more information.\n\nAssuming you have not yet downloaded these files, in the next two cells, we will setup an environment of reference files, download the files, and save the output of the `crds` download process in a log file:"
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\n# ^ The above puts the cell's output into a text file made in the next cell\n# ^^ This avoids a very long printed output\n\n# This sets an env variable for crds to look for the reference data online\n%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n\n# This tells crds where to save the files it downloads\n%env CRDS_PATH ./data/reference/\n\n# This command looks up the pmap file, which tells what ref files to download.\n# It then downloads these to the CRDS_PATH directory.\n# Make sure you have the latest pmap file, found on the CRDS site.\n!crds bestrefs --files data/*raw*.fits --sync-references=2\n!crds bestrefs --update-bestrefs --new-context 'hst_1140.pmap'\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We continue on to creating the CRDS output text file:"
            },
            {
                "type": "code",
                "text": "```python\n\n# This file will contain the output of the last cell\nwith open(outputdir / 'crds_output_1.txt', 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "We'll print the beginning and end of `crds_output_1.txt` just to take a look."
            },
            {
                "type": "code",
                "text": "```python\n\n# Creating a dictionary to store each line as a key & line info as a value\ncrds_output_dict = {}\n\n# Open the file\nwith open(str(outputdir/'crds_output_1.txt'), 'r') as cell_outputs:\n    # Loop through the lines in the text file\n    for linenum, line in enumerate(cell_outputs):\n        # Save each line to the defined dictionary\n        crds_output_dict[linenum] = line[:-1]\n\n# Get the length of the dictionary, aka, how many lines of output\ntotal_lines = len(crds_output_dict)\n\nprint(\"Printing the first and last 5 lines of \" + str(total_lines) +\n      \" lines output by the previous cell:\\n\")\n\nfor i in np.append(range(5), np.subtract(total_lines - 1, range(5)[::-1])):\n    print(f\"Line {i}:   \\t\", crds_output_dict[i])\n\n# Delete the contents of the dict to avoid 'garbage' filling memory\ncrds_output_dict.clear()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**Line 172 of the output should show 0 errors.**\n\nIf you receive errors, you may need to attempt to run the `crds bestrefs` line again. These errors can arise from imperfect network connections. \n\n**It is recommended that you use this new `$lref` folder of reference files for subsequent `CalCOS` use, rather than re-downloading the reference files each time.** To do this (after completing this Notebook): \n- Save this folder somewhere accessibile, i.e. `~/crds_cache`\n- Add a line to your `.bashrc` or similar: `export lref=<Path to your reference file directory>`\n  - If you wish to avoid adding this to your `.bashrc`, simply type the line above into any terminal you wish to run `CalCOS` from\n  - If running `CalCOS` from a Jupyter Notebook, instead add a cell with: `%env lref /Users/<Your Username>/crds_cache/references/hst/cos`"
            },
            {
                "type": "markdown",
                "text": "<a id = runC></a>\n# 3. Processing Raw COS Data Using `CalCOS`\n\n**Now we have all the reference files we need to run the CalCOS pipeline on our data.**\n\nThis following cells which run the pipeline can take a while, sometimes more than **10 minutes!**\n\nBy default, the pipeline also outputs hundreds of lines of text - we will suppress the printing of this text and instead save it to a text file."
            },
            {
                "type": "markdown",
                "text": "<a id = runpyC></a>\n## 3.1. Running `CalCOS`: *From a `Python` Environment*"
            },
            {
                "type": "markdown",
                "text": "**Now, we can run the pipeline program:**\n\nNote that generally, `CalCOS` should be run on an association (`_asn`) file (check out the [Notebook](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/AsnFile/AsnFile.ipynb) we have for creating or editing association files if you wish to alter the `asn` file that we downloaded). In this case, our association file is: `./data/lcxv13040_asn.fits`. You *may* run `CalCOS` directly on `_rawtag` or `_corrtag` exposure files, but this will not produce an `_x1dsum` file and can result in errors for data taken at certain lifetime positions. No matter what type of files you run `CalCOS` on, you should only specify the FUVA segment's file, i.e. the `_rawtag_a` file. If a `rawtag_b` file is in the same directory, `CalCOS` will find both segments' files.\n\nIn this example, we also specify that `verbosity = 2`, resulting in a **very** verbose output, and we specify a directory to put all the output files in: `output/calcos_processed_1`. To avoid polluting this Notebook with more than a thousand lines of the output, we again capture the output of the next cell and save it to `output/output_calcos_1.txt` in the cell below."
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\n# Above ^ again, capture the output and save it in the next cell\n# 1st param specifies which asn file to run the pipeline on\ntry:\n    calcos.calcos(str(datadir/asn_name),\n                  # verbosity param\n                  verbosity=2,\n                  # Save all resulting files in this subdirectory in our outdir\n                  outdir=str(outputdir/\"calcos_processed_1\"))\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\n# This file now contains the output of the previous cell\nwith open(str(outputdir/'output_calcos_1.txt'), 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**Again, we'll print the beginning and end of that file just to take a look and make sure `CalCOS` ran successfully.**"
            },
            {
                "type": "code",
                "text": "```python\n\n# Pair each line with its line number, start at 0\ncalcos_output_dict = {}\n\n# Open the file\nwith open(str(outputdir/'output_calcos_1.txt'), 'r') as cell_outputs:\n    # Loop through each line in output_calcos_1.txt\n    for linenum, line in enumerate(cell_outputs):\n        # Save each line to the dictionary we defined above\n        calcos_output_dict[linenum] = line[:-1]\n\n# Get the length of the dictionary - how many lines of output\ntotal_lines = len(calcos_output_dict)\n\nprint(\"Printing the first and last 5 lines of \"\n      f\"{total_lines} lines output by the previous cell:\\n\")\nfor i in np.append(range(5), np.subtract(total_lines - 1, range(5)[::-1])):\n    print(f\"Line {i}:   \\t\", calcos_output_dict[i])\n\n# Delete the contents of the dictionary to save memory space\ncalcos_output_dict.clear()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = runcliC></a>\n\n## 3.2. Running `CalCOS`: *From the Command Line*\n\nThe syntax for running `CalCOS` from the command line is very similar. Assuming your data files, `lref` directory, and reference files are all where you've told `CalCOS` to look, you can simply run:\n\n```calcos -o directory_to_save_outputs_in filename_asn.fits```\n\n*or, if you want to save a very verbose output to a log file `log.txt`*:\n\n```calcos -v -o directory_to_save_outputs_in filename_asn.fits > log.txt```\n\nTo see the full list of commands, [Table 3.2: Command-line Options for Running `CalCOS` in Unix/Linux/Mac](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration#:~:text=Table%203.3%3A%20Command%2Dline%20Options%20for%20Running%20calcos%20in%20Unix/Linux/Mac), or run the following with the name of the association file:"
            },
            {
                "type": "markdown",
                "text": "```!calcos <PATH_TO_ASN_FILE>```"
            },
            {
                "type": "markdown",
                "text": "<a id = rerunC></a>\n# 4. Re-processing COS Data with Altered Parameters"
            },
            {
                "type": "markdown",
                "text": "<a id = alterswitchC></a>\n## 4.1. Altering the Calibration Switches"
            },
            {
                "type": "markdown",
                "text": "The way to alter how `CalCOS` runs - i.e. which calibrations it performs - is with the **calibration switches** contained in the FITS headers. \n\nThe switches (with the exception of \"XTRACTALG\"), can be set to the values in the following table:\n\n|***Value:***|\"PERFORM\"|\"OMIT\"|\"N/A\"|\n|-|-|-|-|\n|***Meaning:***|Performs the calibration step|Does not perform the calibration step|This step would not make sense for this file|\n\n`XTRACTALG` instead can be set to either \"BOXCAR\" or \"TWOZONE\", to specify the spectral extraction algorithm to be used. For more information, see [Section 3.2.1: \"Overview of TWOZONE extraction\" of the Data Handbook](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview#id-3.2PipelineProcessingOverview-3.2.1OverviewofTWOZONEextraction).\n\nIn the cell below, we get a full list of the switches by name. If you want to learn more about the calibration steps and switches, see [Chapters 2 and 3 of the COS Data Handbook](https://hst-docs.stsci.edu/cosdhb)."
            },
            {
                "type": "code",
                "text": "```python\n\n# Reads the header of the 0th rawfile\nheader = fits.getheader(rawfiles[0])\n# The calibration switches are found in lines 82 - 109 of the header\ncalibswitches = header[82:109]\ncalibswitches\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**Let's begin by switching off all the switches currently set to \"PERFORM\" to a new value of \"OMIT\", in every rawfile:**"
            },
            {
                "type": "code",
                "text": "```python\n\n# Set to True to see a bit more about what is going on here\nverbose = False\n\n# Find each rawfile, i is a counter variable for the files you loop through\nfor rawfile in rawfiles:\n    if verbose:\n        print(rawfile)\n\n    # Read that rawfiles header\n    header = fits.getheader(rawfile)\n\n    # Find all calibration switches\n    corrections = [key for key in list(header.keys()) if \"CORR\" in key]\n\n    # Checking if the value of each switch is 'PERFORM', and changing to 'OMIT'\n    for correction in corrections:\n        if header[correction] == 'PERFORM':\n            if verbose:\n                print(\"switching\\t\", header[correction],\n                      \"\\t\", correction, \"\\tto OMIT\")\n            # Turn off all the calib switches\n            fits.setval(rawfile, correction, value='OMIT', ext=0)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**In this case, `CalCOS` realizes that all the switches are set to \"OMIT\", and exits without doing anything.**"
            },
            {
                "type": "code",
                "text": "```python\n\n# Run CalCOS with all calib switches OFF; allow text output this time\ntry:\n    calcos.calcos(\n        str(datadir/asn_name),\n        verbosity=0,\n        outdir=str(outputdir/\"calcos_processed_2\")\n    )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = switchrunC></a>\n## 4.2. Running `CalCOS` with a Specific Set of Switches\nNow, let's set a single switch to \"PERFORM\", and just run a flat-field correction (\"FLATCORR\") and a pulse-height filter correction (\"PHACORR\"). Set verbosity = 1 or 2 to learn more about how `CalCOS` is working."
            },
            {
                "type": "code",
                "text": "```python\n\nverbose = False\n\n# Find each rawfile, i is a counter variable for the files you loop through\nfor rawfile in rawfiles:\n    if verbose:\n        print(rawfile)\n    # Change the header's keyword FLATCORR to the value PERFORM\n    fits.setval(rawfile, \"FLATCORR\", value='PERFORM', ext=0)\n    # Change the header's keyword PHACORR to the value PERFORM\n    fits.setval(rawfile, \"PHACORR\", value='PERFORM', ext=0)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\n# Above ^ again, capture the output and save it in the next cell\ntry:\n    calcos.calcos(\n        str(datadir/asn_name),\n        verbosity=2,\n        outdir=str(outputdir/\"calcos_processed_3\")\n    )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\n# This file now contains the output of the last cell\nwith open(str(outputdir/'output_calcos_3.txt'), 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = refrunC></a>\n## 4.3. Running `CalCOS` with a Different Reference File\n\nYou may wish to run `CalCOS` with a specific flat file, bad pixel table, or any other reference file. `CalCOS` offers the ability to do just this on a file-by-file basis, by changing the calibration reference file values in the header of your data.\n\nAs an example, we check which calibration files are selected for one of our rawtag files."
            },
            {
                "type": "code",
                "text": "```python\n\n# Read 0th rawfile's header\nheader = fits.getheader(rawfiles[0])\n# The 110th to 138th lines of the header are filled with these reference files\nrefFiles = header[110:138]\n# Get just the keywords i.e. \"FLATFILE\" and \"DEADTAB\"\nrefFile_keys = list(refFiles[2:].keys())\nrefFiles\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "For this section, let's download another Pulse Height Amplitude (`\\_pha`) table file using the `crds` tool:"
            },
            {
                "type": "code",
                "text": "```python\n\n!crds sync --files u1t1616ll_pha.fits --output-dir $lref\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Now we can use the FITS headers to set this new file as the `_pha` file. As a demonstration, let's do this for **only the raw data from segment FUVA** of the FUV detector:\n\n*Note* that we are still only performing two corrections, as all calibration switches aside from `FLATCORR` and `PHACORR` are set to `OMIT`."
            },
            {
                "type": "code",
                "text": "```python\n\n# Find just the FUVA raw files\nrawfiles_segA = glob.glob(str(datadir/'*rawtag_a*.fits'))\n\n# Iterate through each FUVA rawtag file to update the FITS header's PHATAB\nfor rawfileA in rawfiles_segA:\n    print(rawfileA)\n    # Updating the header value\n    with fits.open(rawfileA, mode='update') as hdulist:\n        # Update the 0th header of that FUVA file\n        hdr0 = hdulist[0].header\n        # NOTE: you need the $lref if you put it with your other ref files\n        hdr0[\"PHATAB\"] = 'lref$u1t1616ll_pha.fits'\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "**Finally, let's run `CalCOS` with the new `_pha` file for only the FUVA data:**"
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\ntry:\n    calcos.calcos(\n                str(datadir/asn_name),\n                verbosity=2,\n                outdir=str(outputdir/\"calcos_processed_4\")\n                )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "code",
                "text": "```python\n\n# This file now contains the output of the last cell\nwith open(str(outputdir/'output_calcos_4.txt'), 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<font size=\"5\">Before we go, let's have a look at the spectra that we just calibrated and extracted</font>"
            },
            {
                "type": "markdown",
                "text": "**We'll make a very quick plot to show the two spectra calibrated by STScI's pipeline and by us right now.**\nThe two should agree very well. Small differences may be expected, given that the `RANDSEED` values may be different between the two versions.\n\nMuch more information on reading in and plotting COS spectra can be found in our other tutorial: [Viewing COS Data](https://github.com/spacetelescope/hst_notebooks/blob/main/notebooks/COS/ViewData/ViewData.ipynb).\n\n*(You can ignore the UnitsWarning below)*"
            },
            {
                "type": "code",
                "text": "```python\n\n# Get the STScI calibrated x1dsum spectrum from the archive\nObservations.download_products(Observations.get_product_list(\n                                                Observations.query_criteria(\n                                                        obs_id='lcxv13040')),\n                               mrp_only=True,\n                               download_dir='data/compare/'\n                               )\n\n# Read in this lcxv13040 spectrum\noutput_spectrum = Table.read(\n    str(datadir/'compare/mastDownload/HST/lcxv13040/lcxv13040_x1dsum.fits'))\n\n# Get the wavelength, flux, flux error, and data quality weight the X1DSUM file\n# More info on the DQ_WGT can be found in Section 2.7 of the COS data handbook\nwvln_orig = output_spectrum[1][\"WAVELENGTH\"]\nflux_orig = output_spectrum[1][\"FLUX\"]\nfluxErr_orig = output_spectrum[1][\"ERROR\"]\ndqwgt_orig = output_spectrum[1][\"DQ_WGT\"]\n\n# Convert the data quality (DQ) weight into a boolean to mask the data\ndqwgt_orig = np.asarray(dqwgt_orig,\n                        dtype=bool)\n\n# Read in the spectrum we recently calibrated\noutput_spectrum = Table.read(\n    str(outputdir/'calcos_processed_1/lcxv13040_x1dsum.fits'))\n\n# Get the wavelength, flux, flux error, and data quality weight spectrum\nnew_wvln = output_spectrum[1][\"WAVELENGTH\"]\nnew_flux = output_spectrum[1][\"FLUX\"]\nnew_fluxErr = output_spectrum[1][\"ERROR\"]\nnew_dqwgt = output_spectrum[1][\"DQ_WGT\"]\n\n# Convert the data quality weight into a boolean to mask the data\nnew_dqwgt = np.asarray(new_dqwgt,\n                       dtype=bool)\n\n# Build a 3 row x 1 column figure\nfig, (ax0, ax1, ax2) = plt.subplots(3, 1, figsize=(15, 10))\n\n# Plot the archive's spectrum in the top subplot\nax0.plot(wvln_orig[dqwgt_orig], flux_orig[dqwgt_orig],\n         linewidth=0.5,\n         c='C0',\n         label=\"Processed by the archive\")\n\n# Plot your calibrated spectrum in the middle subplot\nax1.plot(new_wvln[new_dqwgt], new_flux[new_dqwgt],\n         linewidth=0.5,\n         c='C1',\n         label=\"Just now processed by you\")\n\n# Plot the archived & newly calibrated spectra in bottom subplot\nax2.plot(wvln_orig[dqwgt_orig], flux_orig[dqwgt_orig],\n         linewidth=0.5,\n         c='C0',\n         label=\"Processed by the archive\")\nax2.plot(new_wvln[new_dqwgt], new_flux[new_dqwgt],\n         linewidth=0.5,\n         c='C1',\n         label=\"Just now processed by you\")\n\n# Putting the legend on each subplot\nax0.legend(loc='upper center',\n           fontsize=14)\nax1.legend(loc='upper center',\n           fontsize=14)\nax2.legend(loc='upper center',\n           fontsize=14)\n\n# Setting the title of our plot\nax0.set_title(\"Fig 3.1\\nComparison of processed spectra\",\n              size=28)\n\n# Getting rid of the plot's whitespace\nplt.tight_layout()\n\n# Saving the figure to our output directory\n# The 'dpi' parameter stands for 'dots per inch' (the res of the image)\nplt.savefig(str(outputdir/\"fig3.1_compare_plot.png\"),\n            dpi=300)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## Congratulations! You finished this Notebook!\n### There are more COS data walkthrough Notebooks on different topics. You can find them [here](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/COS)."
            },
            {
                "type": "markdown",
                "text": "\n---\n## About this Notebook\n**Author:** Nat Kerman - <nkerman@stsci.edu>\n\n**Updated On:** 2023-03-30\n\n\n> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n\n## Citations\n\nIf you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\nauthors. Follow these links for more information about citations:\n\n* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n* [Citing `numpy`](https://numpy.org/citing-numpy/)\n* [Citing `matplotlib`](https://matplotlib.org/)\n* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n\n---\n\n[Top of Page](#topC)\n<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n\n<br></br>\n<br></br>\n<br></br>"
            }
        ],
        "target": [
            {
                "type": "markdown",
                "text": "<a id=\"topC\"></a>\n\n# Running the COS Data Pipeline (`CalCOS`)\n\n# Learning Goals:\n<font size=\"4 \"> This Notebook is designed to walk the user (<em>you</em>) through:</font>\n\n**1. [Setting up the Environment to Run `CalCOS`](#setupC)**\n\n\\- 1.1. [Prerequisites](#prereqC)\n\n\\- 1.2. [Create Your `conda` Environment](#condaenvC)\n\n\\- 1.3. [Imports and Basic Directories](#impdirC)\n\n\\- 1.4. [Setup a Reference File directory](#lrefC)\n\n\n**2. [Gathering the Data to Run `CalCOS`](#gatherC)**\n\n\\- 2.1. [Downloading the Raw Data](#datadlC)\n\n\\- 2.2. [Gathering Reference Files](#reffileC)\n\n**3. [Processing Raw COS data using `CalCOS`](#runC)**\n\n\\- 3.1. [Running `CalCOS`: *From a `Python` Environment*](#runpyC)\n\n\\- 3.2. [Running `CalCOS`: *From the Command Line*](#runcliC)\n\n**4. [Re-processing COS Data with Altered Parameters](#rerunC)**\n\n\\- 4.1. [Altering the Calibration Switches](#alterswitchC)\n\n\\- 4.2. [Running `CalCOS` with a Specific Set of Switches](#switchrunC)\n\n\\- 4.3. [Running `CalCOS` with a Different Reference File](#refrunC)"
            },
            {
                "type": "markdown",
                "text": "# 0. Introduction\n**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n\n**`CalCOS`** is the data processing pipeline which converts the raw data produced by COS's detectors onboard HST into usable spectral data. It transforms the data from a list of many individual recorded photon interactions into tables of wavelength and flux. \n\n**This tutorial aims to prepare you run the `CalCOS` pipeline to reduce spectral data taken with the COS instrument.** It focuses on COS data taken in `TIME-TAG` mode. \n*Note* that there is another, less commonly used mode, `ACCUM`, which should generally be used only for UV bright targets.\n\n- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/)."
            },
            {
                "type": "markdown",
                "text": "#### Notes for those new to Python/Jupyter/Coding:\n- You will frequently see exclamation points (**!**) or dollar signs (**\\$**) at the beginning of a line of code. These are not part of the actual commands. The exclamation points tell a Jupyter Notebook cell to pass the following line to the command line, and the dollar sign merely indicates the start of a terminal prompt."
            },
            {
                "type": "markdown",
                "text": "<a id = setupC></a>\n# 1. Setting up the Environment to Run `CalCOS`\n\nThe first step to processing your data is setting up an environment from which to run `CalCOS`.\n<a id = prereqC></a>\n## 1.1. Prerequisites\nThis tutorial assumes some basic knowledge of the command line and was built using a unix style shell. Those using a Windows computer will likely have the best results if working within the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\n\nIf you do not already have any distribution of the `conda` tool, see [this page](https://stenv.readthedocs.io/en/latest/getting_started.html#getting-started) for instructions, and install either [`anaconda` (\\~ 3 GB, more beginner friendly, lots of extras you likely won't use)](https://docs.anaconda.com/anaconda/install/), [`miniconda` (\\~ 400 MB, only what you need to make environments)](https://docs.conda.io/en/latest/miniconda.html), or [`mamba` (\\~85 MB, similar to `miniconda` but rewritten in C++).](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html)"
            },
            {
                "type": "markdown",
                "text": "## 1.2. Create Your `conda` Environment\nVerify that the current `conda` environment is activated and determine its name using Python. This will help ensure you are working with the correct environment for running `CalCOS`."
            },
            {
                "type": "code",
                "text": "```python\n\n# Displays name of current conda environment\nfrom os import environ, system\nif \"CONDA_DEFAULT_ENV\" in environ:\n    print(\"You are using:\", environ[\"CONDA_DEFAULT_ENV\"])\nelse:\n    system(\"conda info --envs\")\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## 1.3. Imports and Basic Directories\nPrepare the Python environment by importing the necessary modules and packages that will be used for processing and analyzing the COS data. This includes tools for data handling, accessing FITS files, managing tables, plotting, and interacting with the MAST archive. Also, ensure that your plots will be displayed inline within the notebook."
            },
            {
                "type": "code",
                "text": "```python\n\n# Import necessary libraries for handling and analyzing FITS files, data tables, and plotting\nimport os\nfrom os import system, environ\nimport shutil\nfrom astropy.io import fits\nfrom astropy.table import Table\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure that plots will be displayed inline in the notebook\n%matplotlib inline\n\n# Set up basic directories (Edit the paths as necessary)\nbase_dir = os.path.abspath('.')\ndata_dir = os.path.join(base_dir, 'data')\noutput_dir = os.path.join(base_dir, 'output')\nref_dir = os.path.join(base_dir, 'reference_files')\n\n# Create directories if they don't exist\nos.makedirs(data_dir, exist_ok=True)\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(ref_dir, exist_ok=True)\n\nprint(f\"Base directory: {base_dir}\")\nprint(f\"Data directory: {data_dir}\")\nprint(f\"Output directory: {output_dir}\")\nprint(f\"Reference Files directory: {ref_dir}\")\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "### We will also define a few basic directories in which to place our inputs and outputs.\nDefine the appropriate directories for data inputs and outputs. Ensure these directories exist or create them if they do not."
            },
            {
                "type": "code",
                "text": "```python\n\nimport os\n\n# Define directories for input and output data\ninput_dir = \"data/input\"\noutput_dir = \"data/output\"\n\n# Create directories if they don't exist\nos.makedirs(input_dir, exist_ok=True)\nos.makedirs(output_dir, exist_ok=True)\n\nprint(f\"Input directory: {input_dir}\")\nprint(f\"Output directory: {output_dir}\")\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## Set up the Reference File Directory for `CalCOS`\n\nAssign a system variable to specify the location of the reference files directory for `CalCOS`. Ensure the environment variable `lref` is set to the path where the calibration files necessary for the COS are stored. For a Jupyter Notebook environment, utilize cell magic to accomplish this setup."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom os import environ\n\n# Define the reference file directory and set it as an environment variable\nlref_path = '/path/to/your/reference/files/'\nenviron['lref'] = lref_path\n\n# Verify the environment variable is set correctly\nprint(\"lref is set to:\", environ['lref'])\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Verify the current value of the `lref` system variable to confirm it points to the correct directory for the reference files."
            },
            {
                "type": "code",
                "text": "```python\n\n# Verify the lref environment variable\nimport os\nprint(os.environ.get('lref'))\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "# 2. Gathering the Data to Run `CalCOS`\nDownload the necessary raw data and association files for the specified observation id from the MAST archive. Filter the files to ensure you obtain the `_asn` and `_rawtag` FITS files for the COS/FUV data associated with the quasar 3C48. Then proceed to download them into the designated data directory."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom astroquery.mast import Observations\n\n# Define the observation id\nobs_id = \"LCX702030\"\n\n# Use astroquery to search for observations\nobs_table = Observations.query_criteria(obs_id=obs_id, instrument_name=\"COS/FUV\")\n\n# Filter the results to get only rawtag and association files\nproducts = Observations.get_product_list(obs_table)\nfiltered_products = Observations.filter_products(products,\n                                                productSubGroupDescription=[\"ASN\", \"RAWTAG\"])\n\n# Download the filtered products to the specified data directory\nObservations.download_products(filtered_products, download_dir=str(datadir))\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "After downloading the raw data and association files, relocate these files so they are all within the same directory. Clear any empty nested subdirectories that no longer contain necessary files."
            },
            {
                "type": "code",
                "text": "```python\n\n# Move all downloaded files to the data directory since 'download_products' may create subdirectories\nfor file in rawtag_locs['Local Path']:\n    Path(file).rename(datadir / Path(file).name)\n\nfor file in asn_locs['Local Path']:\n    Path(file).rename(datadir / Path(file).name)\n\n# Clean up any empty subdirectories after moving the files\nfor subdir in datadir.iterdir():\n    if subdir.is_dir():\n        try:\n            subdir.rmdir()\n        except OSError:\n            pass  # Directory is not empty\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## 2.2. Gathering Reference Files\nDetermine the CRDS context of the first raw FITS file in your data directory. This will help in understanding which calibration files were used most recently by the STScI for your data."
            },
            {
                "type": "code",
                "text": "```python\n\nfrom astropy.io import fits\n\n# Open the first raw FITS file in the data directory\nwith fits.open(next(datadir.glob('*rawtag*.fits'))) as hdulist:\n    crds_context = hdulist[0].header.get('CRDS_CTX', 'undefined')\n\nprint(\"CRDS context for this data is:\", crds_context)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Download the necessary reference files using the `crds` tool, ensuring that the tool accesses reference data online and saves it in a specified directory. Capture the cell's output to a text file to log the download process."
            },
            {
                "type": "code",
                "text": "```python\n\n# Download CRDS reference files using the specific crds context and path\n!crds bestrefs --update-bestrefs --files {rawfiles[0]} --sync-references=1 --fetch-references --output-dir ./data/reference/references/hst/cos/ > ./download_log.txt\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Create a text file to store the output of the CRDS process. This output will provide a record of the actions taken during the reference files download."
            },
            {
                "type": "code",
                "text": "```python\n\n# Write the CRDS tool output to a text file\nwith open('crds_download.txt', 'w') as file:\n    file.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Display the first and last five lines of the output from the CRDS download process to ensure the actions were performed correctly."
            },
            {
                "type": "code",
                "text": "```python\n\n# Display the first 5 lines of the CRDS process output\nprint(\"\\n\".join(cap.stdout.splitlines()[:5]))\n\n# Display the last 5 lines of the CRDS process output\nprint(\"\\n\".join(cap.stdout.splitlines()[-5:]))\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = runC></a>\n# 3. Processing Raw COS Data Using `CalCOS`\n\n**Now we have all the reference files we need to run the CalCOS pipeline on our data.**\n\nThis following cells which run the pipeline can take a while, sometimes more than **10 minutes!**\n\nBy default, the pipeline also outputs hundreds of lines of text - we will suppress the printing of this text and instead save it to a text file."
            },
            {
                "type": "markdown",
                "text": "## 3.1. Running `CalCOS`: *From a `Python` Environment*\nUse the `CalCOS` program within a Python environment to process the raw COS data, particularly focusing on an association (`_asn`) FITS file. Specify the association file, verbosity level, and the directory for output files. Suppress the output from being displayed directly by capturing it to a separate log file."
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\nfrom calcos import calcos\n\n# Run CalCOS from within python. This will create many files in the output directory\ncalcos.calcos(datadir / asn_name, verbosity=2, outdir=str(outputdir))\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Write the captured output from running the `CalCOS` program to a text file within the output directory. This will store the potentially verbose output for later review."
            },
            {
                "type": "code",
                "text": "```python\n\n# Write the captured output to a text file\nwith open(outputdir / \"calcos_output_log.txt\", 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Print the first and last five lines of the output from the `CalCOS` run stored in the text file to verify that the process ran successfully without printing the entire contents directly."
            },
            {
                "type": "code",
                "text": "```python\n\n# Pair each line with its line number, start at 0\ncalcos_output_dict = {}\n\n# Open the file\nwith open(str(outputdir/'output_calcos_1.txt'), 'r') as cell_outputs:\n    # Loop through each line in output_calcos_1.txt\n    for linenum, line in enumerate(cell_outputs):\n        # Save each line to the dictionary we defined above\n        calcos_output_dict[linenum] = line[:-1]\n\n# Get the length of the dictionary - how many lines of output\ntotal_lines = len(calcos_output_dict)\n\nprint(\"Printing the first and last 5 lines of \"\n      f\"{total_lines} lines output by the previous cell:\\n\")\nfor i in np.append(range(5), np.subtract(total_lines - 1, range(5)[::-1])):\n    print(f\"Line {i}:   \\t\", calcos_output_dict[i])\n\n# Delete the contents of the dictionary to save memory space\ncalcos_output_dict.clear()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "<a id = runcliC></a>\n\n## 3.2. Running `CalCOS`: *From the Command Line*\n\nThe syntax for running `CalCOS` from the command line is very similar. Assuming your data files, `lref` directory, and reference files are all where you've told `CalCOS` to look, you can simply run:\n\n```calcos -o directory_to_save_outputs_in filename_asn.fits```\n\n*or, if you want to save a very verbose output to a log file `log.txt`*:\n\n```calcos -v -o directory_to_save_outputs_in filename_asn.fits > log.txt```\n\nTo see the full list of commands, [Table 3.2: Command-line Options for Running `CalCOS` in Unix/Linux/Mac](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration#:~:text=Table%203.3%3A%20Command%2Dline%20Options%20for%20Running%20calcos%20in%20Unix/Linux/Mac), or run the following with the name of the association file:"
            },
            {
                "type": "markdown",
                "text": "```!calcos <PATH_TO_ASN_FILE>```"
            },
            {
                "type": "markdown",
                "text": "<a id = rerunC></a>\n# 4. Re-processing COS Data with Altered Parameters"
            },
            {
                "type": "markdown",
                "text": "## 4.1. Altering the Calibration Switches\nAccess the header of a specified raw FITS file to identify the calibration switches. Extract and display these calibration switches to see their current state."
            },
            {
                "type": "code",
                "text": "```python\n\n# Fetch header from the FITS file\nhdr = fits.getheader(rawfiles[0])\n\n# Extract calibration switches from the header\ncalib_switches = {key: hdr[key] for key in hdr if key.endswith('CORR')}\n\n# Display the current state of the calibration switches\nfor switch, state in calib_switches.items():\n    print(f\"{switch}: {state}\")\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Toggle all calibration switches currently set to \"PERFORM\" to \"OMIT\" across every raw data file, updating each FITS file's header accordingly."
            },
            {
                "type": "code",
                "text": "```python\n\n# Loop through each raw file\nfor rawfile in rawfiles:\n    # Open the FITS file for updating\n    with fits.open(rawfile, mode='update') as hdul:\n        # Access the header of the primary HDU\n        header = hdul[0].header\n        \n        # Loop through the relevant calibration switches\n        for switch in range(82, 109):\n            # Check if the switch is set to 'PERFORM'\n            if header[switch] == 'PERFORM':\n                # Change it to 'OMIT'\n                header[switch] = 'OMIT'\n        \n        # Save the update to the FITS file by closing.\n        hdul.flush()\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Attempt to run the `CalCOS` pipeline with all calibration switches set to \"OMIT\". Observe how `CalCOS` handles this configuration to verify that it exits without executing unnecessary processes."
            },
            {
                "type": "code",
                "text": "```python\n\n# Run CalCOS with all calib switches OFF; allow text output this time\ntry:\n    calcos.calcos(\n        str(datadir/asn_name),\n        verbosity=0,\n        outdir=str(outputdir/\"calcos_processed_2\")\n    )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## 4.2. Running `CalCOS` with a Specific Set of Switches\nWith the raw files set up, adjust two specific calibration parameters: the flat-field correction (`FLATCORR`) and the pulse-height filter correction (`PHACORR`). Change these settings so they are enabled to perform these corrections, while all other calibration switches remain disabled."
            },
            {
                "type": "code",
                "text": "```python\n\n# Display changed switches if verbose is True\nverbose = True\n\n# Toggle on FLATCORR and PHACORR for each rawfile:\nfor rawfile in rawfiles:\n    if verbose:\n        print(rawfile)\n    # Update only FLATCORR and PHACORR to 'PERFORM'\n    fits.setval(rawfile, 'FLATCORR', value='PERFORM', ext=0)\n    fits.setval(rawfile, 'PHACORR', value='PERFORM', ext=0)\n\n    # To identify other calibration switches and verify they remain OMIT\n    corrections = [key for key in fits.getheader(rawfile).keys() \n                   if \"CORR\" in key]\n    for correction in corrections:\n        val = fits.getval(rawfile, correction)\n        if correction not in ['FLATCORR', 'PHACORR']:\n            fits.setval(rawfile, correction, value='OMIT', ext=0)\n            if verbose:\n                print(f\"switching {correction} to OMIT from {val}\")\n        else:\n            if verbose:\n                print(f\"{correction} set to {val}\")\n\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Capture the output from running the `CalCOS` program with these specific calibration switches set to \"PERFORM\". Ensure the output is stored in a file for review and future reference without printing directly in the notebook."
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\n# Above ^ again, capture the output and save it in the next cell\ntry:\n    calcos.calcos(\n        str(datadir/asn_name),\n        verbosity=2,\n        outdir=str(outputdir/\"calcos_processed_3\")\n    )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Store the output of the previous `CalCOS` execution into a text file inside the output directory. This will document the activity and results of processing with the chosen calibration settings."
            },
            {
                "type": "code",
                "text": "```python\n\n# This file now contains the output of the last cell\nwith open(str(outputdir/'output_calcos_3.txt'), 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## 4.3. Running `CalCOS` with a Different Reference File\nExamine the FITS header of the first raw data file to identify the calibration files currently in use for processing. Display the relevant section containing these file references."
            },
            {
                "type": "code",
                "text": "```python\n\n# The keywords containing refrences are between lines 33 and 66 on the header\nheader = fits.getheader(rawfiles[0])\ncalib_files = header[33:67]\ncalib_files\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Use the `crds` tool to download an alternative Pulse Height Amplitude (`_pha`) file and save it to the current reference file directory."
            },
            {
                "type": "code",
                "text": "```python\n\n# Set the environment variable to specify to download from the CRDS server\n%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n\n# Set the directory where CRDS should save the reference files\n%env CRDS_PATH ./data/reference/\n\n# Download an alternative _pha file to the CRDS_PATH directory\n!crds bestrefs --download --files data/*raw*.fits --sync-references=2 --new-context=hst_1140.pmap --types=PHA\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Set the downloaded `_pha` file as the Pulse Height Amplitude reference for the FUVA segment of your raw COS data. This involves updating the corresponding FITS headers to use the newly acquired file."
            },
            {
                "type": "code",
                "text": "```python\n\n# Set the keyword \"PHATAB\" to the value \"u1t1616ll_pha.fits\" in the rawfiles\nfor rawfile in rawfiles:\n    fits.setval(rawfile, \"PHATAB\", value='u1t1616ll_pha.fits', ext=0)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Execute the `CalCOS` program to process the FUVA segment with the new `_pha` reference file, ensuring that only the FUVA-specific data is calibrated using this alternative reference."
            },
            {
                "type": "code",
                "text": "```python\n\n%%capture cap --no-stderr\ntry:\n    calcos.calcos(\n                str(datadir/asn_name),\n                verbosity=2,\n                outdir=str(outputdir/\"calcos_processed_4\")\n                )\nexcept RuntimeError as e:\n    print('An error occured, ', e)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "Store the output of the `CalCOS` execution, tailored for the FUVA segment with the updated reference file, into a designated text file within your output directory."
            },
            {
                "type": "code",
                "text": "```python\n\n# This file now contains the output of the last cell\nwith open(str(outputdir/'output_calcos_4.txt'), 'w') as f:\n    f.write(cap.stdout)\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "After processing, generate a plot comparing the calibrated spectra to ensure they agree. Details on displaying COS data spectra can be found in the provided tutorial link."
            },
            {
                "type": "code",
                "text": "```python\n\n# Using matplotlib to plot spectra\nfrom astropy.io import fits\nimport matplotlib.pyplot as plt\n\n# Define a function to plot the calibrated spectrum for FUV segments\ndef plot_fuv_spectrum(segment):\n    # Get the x1d files from the latest CalCOS run directory\n    x1d_files = sorted(glob.glob(str(outputdir/'calcos_processed_4/'f'*x1d{segment}.fits')))\n\n    # Initiate plot\n    plt.figure(figsize=(14, 7))\n    # Iterate over each output x1d file\n    for x1d_file in x1d_files:\n        with fits.open(x1d_file) as x1d:\n            filename = x1d[0].header['FILENAME']\n            wavelength = x1d[1].data['WAVELENGTH']\n            flux = x1d[1].data['FLUX']\n            plt.plot(wavelength, flux, label=filename)\n\n    plt.title(f'Spectra for FUVA Segment {segment}')\n    plt.xlabel('Wavelength (Angstrom)')\n    plt.ylabel('Flux (erg / s / cm^2 / Angstrom)')\n    plt.legend()\n    plt.show()\n\n# Plot the FUVA data\nplot_fuv_spectrum('A')\n\n```",
                "output": ""
            },
            {
                "type": "markdown",
                "text": "## Congratulations! You finished this Notebook!\n### There are more COS data walkthrough Notebooks on different topics. You can find them [here](https://github.com/spacetelescope/hst_notebooks/tree/main/notebooks/COS)."
            },
            {
                "type": "markdown",
                "text": "---\n## About this Notebook\n**Author:** Nat Kerman - <nkerman@stsci.edu>\n\n**Updated On:** 2023-03-30\n\n\n> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n\n## Citations\n\nIf you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\nauthors. Follow these links for more information about citations:\n\n* [Citing `astropy`](https://docs.astropy.org/en/stable/index.html)\n* [Citing `numpy`](https://numpy.org/citing-numpy/)\n* [Citing `matplotlib`](https://matplotlib.org/)\n* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n\n---\n\n[Top of Page](#topC)\n<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n\n<br></br>\n<br></br>\n<br></br>"
            }
        ],
        "alignments": [
            {
                "matching": [
                    0,
                    0
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    1,
                    1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    2,
                    2
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    3,
                    3
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    4,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    5,
                    4
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    6,
                    5
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    7,
                    6
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    8,
                    7
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    9,
                    8
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    10,
                    9
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    11,
                    10
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    12,
                    11
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    13,
                    12
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    14,
                    13
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    15,
                    14
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    16,
                    15
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    17,
                    16
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    18,
                    17
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    19,
                    18
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    20,
                    19
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    21,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    22,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    23,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    24,
                    20
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    25,
                    21
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    26,
                    22
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    27,
                    23
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    28,
                    24
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    29,
                    25
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    30,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    31,
                    26
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    32,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    33,
                    27
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    34,
                    28
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    29
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    35,
                    30
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    36,
                    31
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    37,
                    32
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    38,
                    33
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    39,
                    34
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    40,
                    35
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    41,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    42,
                    36
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    43,
                    37
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    44,
                    38
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    45,
                    39
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    46,
                    40
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    47,
                    41
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    48,
                    42
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    49,
                    43
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    44
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    50,
                    45
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    46
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    51,
                    47
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    52,
                    48
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    53,
                    49
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    54,
                    50
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    55,
                    51
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    56,
                    52
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    57,
                    53
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    58,
                    54
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    59,
                    55
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    -1,
                    56
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    60,
                    57
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "code"
            },
            {
                "matching": [
                    61,
                    -1
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    62,
                    58
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    63,
                    59
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "\nASSIGNED VAR TEST:\n\n",
                "cell_type": "code"
            },
            {
                "matching": [
                    64,
                    60
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            },
            {
                "matching": [
                    65,
                    61
                ],
                "flagged": false,
                "starred": false,
                "evaluable": false,
                "edited_text": "<DEFAULT>",
                "comments": "",
                "cell_type": "markdown"
            }
        ]
    }
]